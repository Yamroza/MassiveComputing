{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1be9e258-6ff8-4724-aa4c-71624be77513",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "16c08e7f-e607-48da-b66a-9102f1d5305a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import ArrayType, StringType, LongType, StructType,  StructField, IntegerType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d8fa147c-677e-42e6-99fc-cf8f3568c533",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da91f9fe-d028-48be-af50-239f8ef26eed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data2 = [(1,[2,4]),\n",
    "    (2,[1,3,5]),\n",
    "    (3,[4]),\n",
    "    (4,[1,2]),\n",
    "    (5,[])\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"id\", IntegerType(),True), \\\n",
    "    StructField(\"next\", ArrayType(elementType= LongType()),True)\n",
    "    ])\n",
    " \n",
    "ForwardDF = spark.createDataFrame(data=data2,schema=schema)\n",
    "ForwardPDF= ForwardDF.toPandas()\n",
    "ForwardDF_WC = ForwardDF.select(\"id\", \"next\", F.size(\"next\").alias('n_next'))\n",
    "ForwardPDF_WC = ForwardDF_WC.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7bbb4ce3-594b-4b8d-95ac-4fed3713c5e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def reverseId(id,links):\n",
    "    if (len(links)>0):\n",
    "        reverse = [ (tgt_id,id) for tgt_id in links ]\n",
    "    else:\n",
    "        reverse=[]\n",
    "    return reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "59989237-19fb-4c5e-9299-971e4ad43002",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ForwardRDD = ForwardDF_WC.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6bd5f233-b1ae-406e-b2bd-0af0363809ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ReverseRDD=(ForwardRDD\n",
    " .flatMap(lambda r: reverseId(r.id,r.next))\n",
    " .groupByKey()\n",
    " .map(lambda r: (r[0],list(r[1])))\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aeba28cc-33f0-419f-b269-e6fd21b5ce54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reverseDF=spark.createDataFrame(ReverseRDD,[\"id1\",\"prev\"])\n",
    "reverseDF_WC = reverseDF.select(\"id1\", \"prev\", F.size(\"prev\").alias(\"n_prev\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c74f211d-e359-4811-bdc0-0970785c7af9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|id1|  prev|\n",
      "+---+------+\n",
      "|  1|[2, 4]|\n",
      "|  2|[1, 4]|\n",
      "|  3|   [2]|\n",
      "|  4|[1, 3]|\n",
      "|  5|   [2]|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reverseDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96d8fa1f-7ad6-49d8-b06e-ef44e89978b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---------+------+----+\n",
      "| id|  prev|n_prev|     next|n_next|rank|\n",
      "+---+------+------+---------+------+----+\n",
      "|  5|   [2]|     1|       []|     0| 0.2|\n",
      "|  1|[2, 4]|     2|   [2, 4]|     2| 0.2|\n",
      "|  3|   [2]|     1|      [4]|     1| 0.2|\n",
      "|  2|[1, 4]|     2|[1, 3, 5]|     3| 0.2|\n",
      "|  4|[1, 3]|     2|   [1, 2]|     2| 0.2|\n",
      "+---+------+------+---------+------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ReverseDF = reverseDF_WC.join(ForwardDF_WC, ForwardDF_WC.id == reverseDF_WC.id1).select(\"id\",\"prev\",\"n_prev\",\"next\",\"n_next\").withColumn(\"rank\", F.lit(0.2))\n",
    "ReverseDF.show()\n",
    "ReversePDF = ReverseDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e656f48-dffe-4e58-9a5a-15143566f24a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ReverseDF.select(\"prev\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7be33847-026c-4a72-a5ca-706f6ffbd80b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def new_pagerank(list_of_ids, pagerank):\n",
    "    '''\n",
    "    1 - Iterar por los diferentes ids de los preccessors \n",
    "    2 - Hacer el sumatorio ponderado (formula de PageRank) \n",
    "    '''\n",
    "    # PageRankPDF= broadcast_PageRankPDF.value\n",
    "    new_page_rank = 0.0\n",
    "    N= pagerank.shape[0]-1\n",
    "        \n",
    "    for k in list_of_ids: \n",
    "        temp= pagerank\n",
    "        line = temp.query(f'id== {k}', inplace = False)\n",
    "        r = float(line['rank'])\n",
    "        s = float(line['n_next'])\n",
    "        #if s ==0:\n",
    "        #    new_page_rank += r/N   \n",
    "        #else:\n",
    "        new_page_rank += r/s \n",
    "    return float(new_page_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "53d9539e-8ad2-40d7-8dfa-d314d83aab6f",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=============================================>        (170 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(rank=0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sum2= ReverseDF.filter(ReverseDF[\"n_next\"]==0).select(\"rank\").rdd.reduce(add)\n",
    "a=0.0\n",
    "for i in sum2: a += i \n",
    "print(sum2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9dcd85cc-9b27-4d77-a417-bcb96477475f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def new_pagerank_nosuccessors(pagerank,size):\n",
    "    '''\n",
    "    Takes into account all the ids that do not have any succesor, and shares their rank with the whole dataframe  \n",
    "    '''\n",
    "\n",
    "    withNextDF = pagerank.filter(pagerank[\"n_next\"]!=0)\n",
    "    withoutNextDF = pagerank.filter(pagerank[\"n_next\"]==0)\n",
    "    \n",
    "    temp= withoutNextDF.select(\"rank\").rdd.reduce(add)\n",
    "    sum= 0.0\n",
    "    for i in temp: sum += i\n",
    "    \n",
    "    withNextDF2 = withNextDF.withColumn(\"rank\",withNextDF.rank + F.lit(sum/(size-1)))\n",
    "    UnionDF = withoutNextDF.unionByName(withNextDF2)\n",
    "    \n",
    "    return UnionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---------+------+----+\n",
      "| id|  prev|n_prev|     next|n_next|rank|\n",
      "+---+------+------+---------+------+----+\n",
      "|  5|   [2]|     1|       []|     0| 0.2|\n",
      "|  1|[2, 4]|     2|   [2, 4]|     2|0.25|\n",
      "|  3|   [2]|     1|      [4]|     1|0.25|\n",
      "|  2|[1, 4]|     2|[1, 3, 5]|     3|0.25|\n",
      "|  4|[1, 3]|     2|   [1, 2]|     2|0.25|\n",
      "+---+------+------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_pagerank_nosuccessors(ReverseDF,5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d3dc8c5c-86b2-4204-bc1c-b932294ccdd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "count= 0\n",
    "temp= 2\n",
    "# broadcast_PageRankPDF= sc.broadcast(ReversePDF)\n",
    "PageRankPDF= ReversePDF\n",
    "size = PageRankPDF.shape[0]\n",
    "PrevRankPDF= PageRankPDF\n",
    "\n",
    "while (count < 20) and (temp > 0.0001):\n",
    "    conv= 0.0\n",
    "    # First we take into account the contribution of the usual pages\n",
    "    udf_new_pagerank = udf(lambda l: new_pagerank(l , PageRankPDF), FloatType())\n",
    "    NewPageRankDF = ReverseDF.select(\"id\",udf_new_pagerank(\"prev\").alias(\"rank\"),\"n_next\")\n",
    "    #PageRankPDF= NewPageRankDF.toPandas() \n",
    "    # Then the contribution of the non successor pages \n",
    "    NewPageRankDF_2 = new_pagerank_nosuccessors(NewPageRankDF, size)\n",
    "    PageRankPDF = NewPageRankDF_2.toPandas() \n",
    "    \n",
    "    temp = abs(PageRankPDF[\"rank\"] - PrevRankPDF[\"rank\"]).sum()/size\n",
    "       \n",
    "    PrevRankPDF = PageRankPDF\n",
    "    count += 1 \n",
    "\n",
    "FinalPageRankDF = NewPageRankDF_2.orderBy(F.desc(\"rank\")).select(\"id\", \"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "abcaf289-bcfc-468c-a9c5-d8cd7b7fad09",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 272:================================================>    (369 + 8) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|               rank|\n",
      "+---+-------------------+\n",
      "|  4|   0.31666667945683|\n",
      "|  2| 0.2166666705161333|\n",
      "|  1|0.18333333916962147|\n",
      "|  3|0.08333333767950535|\n",
      "|  5|0.06666667014360428|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 272:===================================================> (392 + 8) / 400]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "FinalPageRankDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FinalNotebook_test",
   "notebookOrigID": 1109003329934594,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
