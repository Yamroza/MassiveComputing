{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Authors of the homework:**\n",
        "+ Mireia Izquierdo\n",
        "+ Aleksandra Jamr√≥z"
      ],
      "metadata": {
        "id": "ofQPMILNx6zI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGP4k4rPTpNG"
      },
      "outputs": [],
      "source": [
        "#Uncomment next line if you are using Google Colaboratory\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rHW7jWHuTugs"
      },
      "outputs": [],
      "source": [
        "import  numpy  as  np\n",
        "import  pycuda.autoinit\n",
        "from    pycuda.compiler import SourceModule\n",
        "import  pycuda.driver as  drv\n",
        "import  pycuda.gpuarray as  gpuarray\n",
        "import  pycuda.tools as gtools\n",
        "from numpy import linalg as la\n",
        "from IPython import display\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yoPtuTz0pTm"
      },
      "source": [
        "# Guide to using tiled algorithms\n",
        "When we want to use tiled memory based algorithms, we need to analize the following steps:\n",
        "\n",
        "1) Tiled Memory Size: What information we will share across all the execution threads in a execution block\n",
        "\n",
        "2) Assign the memory position to each execution thread with memory coalesence\n",
        "\n",
        "3) Fill the Tiled Memory in parallel\n",
        "\n",
        "4) Assign to some threads the extra data needed for the algorithms\n",
        "\n",
        "5) Synchronize the filling memory execution\n",
        "\n",
        "6) Each thread execute his individual task\n",
        "\n",
        "7) Synchronize the execution task\n",
        "\n",
        "8) End the execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDFdRuR-eHCy"
      },
      "source": [
        "# TILED REDUCTION ARRAY\n",
        "The algorithm of reduction (which calculates the sum of all elements in an array), works as follows:\n",
        "\n",
        "![image.png](attachment:d6e8dd16-0624-4d98-af7c-5a8f36bd28c5.png)\n",
        "\n",
        "* Tiled memory size: The tile will contain twice the times of the number of threads assigned\n",
        "* Each thread in the execution block copies the data from global memory to the assigned memory place\n",
        "* No extra data need (for this task)\n",
        "* In each iteration\n",
        "    * Add the possition assigned and the next available data (indexed by the stride)\n",
        "    * This will work until the stride exceeds the block size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ykQwHPFRTw68"
      },
      "outputs": [],
      "source": [
        "tiled_reduction_src = \"\"\"\n",
        "__global__ void tiled_reduction( float *v, float *c, int N){\n",
        "\n",
        "  const int BLOCK_SIZE = 1024;\n",
        "\n",
        "  __shared__ float partialSum[ 2 * BLOCK_SIZE ]; //The array dimensions MUST be constants\n",
        "\n",
        "  unsigned int t = threadIdx.x;\n",
        "  unsigned int start = 2 * blockIdx.x * blockDim.x;\n",
        "\n",
        "  \n",
        "  //fill the tile memory\n",
        "  //each thread will fill the memory position start +t and start+blockDim.x+t\n",
        "  //each consecutive execution thread (threadIdx.x) will access to coalesced memory in both steps\n",
        "  \n",
        "  if ( (start+t) < N) \n",
        "    partialSum[t] = v[start+t];\n",
        "  else \n",
        "    partialSum[t] = 0;\n",
        "\n",
        "  if ((start+blockDim.x+t) < N)\n",
        "    partialSum[blockDim.x+t] = v[start+blockDim.x+t];\n",
        "  else\n",
        "    partialSum[blockDim.x+t] = 0;\n",
        "\n",
        "  //Here we will wait until all execution threads fill te memory\n",
        "  __syncthreads();\n",
        "\n",
        "  for ( unsigned int stride = 1; stride <=blockDim.x; stride*=2 ) {\n",
        "    __syncthreads();\n",
        "    if ( t % stride == 0)\n",
        "      partialSum[2*t]+=partialSum[2*t+stride];\n",
        "  }\n",
        "  c[blockIdx.x] = partialSum[0];\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8998d2i0pTr"
      },
      "source": [
        "Here we cannot automatically edit the source template to use the string % function to replace character chains in the string variable by other values. \n",
        "\n",
        "The problem when using modern strings formating (format method or f-strings) is the collision of the use of {} symbols, and in the previos source code, the presence of modulus operator (%) collides with the string subtitution.\n",
        "\n",
        "In further codes we will use it to be able to substitute constants values for external variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4fIVY60nWWE9"
      },
      "outputs": [],
      "source": [
        "#Set block size to 1024, the maximum\n",
        "BLOCK_SIZE = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0-nV2g20pTs",
        "outputId": "f06d3571-4088-42a8-933f-9f8566ac8cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "__global__ void tiled_reduction( float *v, float *c, int N){\n",
            "\n",
            "  const int BLOCK_SIZE = 1024;\n",
            "\n",
            "  __shared__ float partialSum[ 2 * BLOCK_SIZE ]; //The array dimensions MUST be constants\n",
            "\n",
            "  unsigned int t = threadIdx.x;\n",
            "  unsigned int start = 2 * blockIdx.x * blockDim.x;\n",
            "\n",
            "  \n",
            "  //fill the tile memory\n",
            "  //each thread will fill the memory position start +t and start+blockDim.x+t\n",
            "  //each consecutive execution thread (threadIdx.x) will access to coalesced memory in both steps\n",
            "  \n",
            "  if ( (start+t) < N) \n",
            "    partialSum[t] = v[start+t];\n",
            "  else \n",
            "    partialSum[t] = 0;\n",
            "\n",
            "  if ((start+blockDim.x+t) < N)\n",
            "    partialSum[blockDim.x+t] = v[start+blockDim.x+t];\n",
            "  else\n",
            "    partialSum[blockDim.x+t] = 0;\n",
            "\n",
            "  //Here we will wait until all execution threads fill te memory\n",
            "  __syncthreads();\n",
            "\n",
            "  for ( unsigned int stride = 1; stride <=blockDim.x; stride*=2 ) {\n",
            "    __syncthreads();\n",
            "    if ( t % stride == 0)\n",
            "      partialSum[2*t]+=partialSum[2*t+stride];\n",
            "  }\n",
            "  c[blockIdx.x] = partialSum[0];\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#prints the code from above \n",
        "print(tiled_reduction_src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kjuErm1A0pTs"
      },
      "outputs": [],
      "source": [
        "#use SourceModule function from PyCUDA to compile raw inline CUDA C code into usable kernels that we can launch from Python\n",
        "mod = SourceModule(tiled_reduction_src) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "phFRFRem0pTt"
      },
      "outputs": [],
      "source": [
        "#create array, datatype int32\n",
        "datasize = np.int32(1000000)\n",
        "#output of datasize = 1000000  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Kn-DuDDB0pTt"
      },
      "outputs": [],
      "source": [
        "tiled_reduction = mod.get_function(\"tiled_reduction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oN4nSpbKWdSk"
      },
      "outputs": [],
      "source": [
        "#create array filled with random floats sampled from a univariate standard normal distribution\n",
        "data = np.random.randn(datasize).astype(np.float32)\n",
        "\n",
        "#return a GPUArray that is an exact copy of the numpy array data, i.e. transfer the array to the GPU\n",
        "data_gpu = gpuarray.to_gpu(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UasVzUSoYV8E"
      },
      "outputs": [],
      "source": [
        "#define the size for the blocks\n",
        "block_size = (int(BLOCK_SIZE),1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_72v3Ef9btTA"
      },
      "outputs": [],
      "source": [
        "#define the number of blocks by dividing the size of data by the previously defined blocksize\n",
        "numblocks = int(np.ceil(datasize/BLOCK_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SBkA74pHcala"
      },
      "outputs": [],
      "source": [
        "#allocate an empty array of float32 values on the GPU\n",
        "c_gpu = gpuarray.empty((numblocks,1),np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p1P4majmb2-c"
      },
      "outputs": [],
      "source": [
        "#define the grid size. Here: grid size of n*1\n",
        "grid_size = (numblocks,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ke13jd3wb56p"
      },
      "outputs": [],
      "source": [
        "#data_gpu: GPU array to store the input image\n",
        "#c_gpu: empty CPU array\n",
        "#datasize: specifies how many pixels are in each tile of the grid\n",
        "#grid/block: specify how large each tile/block is \n",
        "start_t = time.time()\n",
        "tiled_reduction(data_gpu,\n",
        "                c_gpu,\n",
        "                datasize,\n",
        "                grid = grid_size,\n",
        "                block = block_size)\n",
        "end_t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-v572IHAc7ly"
      },
      "outputs": [],
      "source": [
        "c = c_gpu.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cEVpW3CadCqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f55c80-1da4-4eaa-b7c0-f1c61249637e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1882.9878161986908"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sum(data)\n",
        "#output is different each time, for instance:\n",
        "#1380.650449003166 ; then 2325.0763068947194"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CzSQdkcgdD3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15a35ee-f403-4641-925e-16a6e472ef37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1882.9878"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "np.sum(c)\n",
        "#output is different each time, for instance:\n",
        "#1380.6504 ; then 2325.0764"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute & print the time difference between start & end time, i.e. time taken to process\n",
        "time_diff = end_t - start_t\n",
        "print(time_diff)\n",
        "#output: approx 0.000210 ; meaning it takes very little time. It is efficient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNaDAeOk2VKh",
        "outputId": "0808ec14-67c5-4b14-e15b-415574c1993b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0026144981384277344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRqu_6mHfpvc"
      },
      "source": [
        "# 1D Convolution\n",
        "\n",
        "The algorithm to implement will calculate the convolution between 2 arrays.\n",
        "\n",
        "The shortest array, called system mask, system response, represents the exit of a system to a special signal called Dirac's delta (signal of infinite height, but limited area under the curve).\n",
        "\n",
        "The second array (the longest one) is the signal to be shaped by our system.\n",
        "\n",
        "Based on this mathematical operation the filter works.\n",
        "\n",
        "The Image Filter algorithms are 2 dimensional convolutions.<br>\n",
        "\n",
        "![image.png](attachment:17f3b373-5760-4edb-b6b3-a233aef56fe3.png)\n",
        "\n",
        "The problem with the tile algorithms is that we need extra data to calculate the correct convolution (halos)<br>\n",
        "\n",
        "![image.png](attachment:e3bc106b-14eb-4935-8de3-549c7a225578.png)\n",
        "\n",
        "The steps to implement the algorithm are:\n",
        "\n",
        "* Tiled memory size: The tile will contains not only the block size elements, but also the system mask length - 1, to store the halos. Also, we need to store in memory the shared memory the system mask. \n",
        "* Each thread in the execution block copy the data from global memory to the assigned memory place, and few of them will fill the halos.<br>\n",
        "\n",
        "![image.png](attachment:3a76556c-c652-49c4-821a-c5be890b13aa.png)\n",
        "\n",
        "<br/>\n",
        "\n",
        "![image.png](attachment:83d342d6-57dc-439a-8dc7-190a5dc8a10b.png)\n",
        "<br/>\n",
        "\n",
        "![image.png](attachment:5d4f3aa2-d27b-4639-94fc-e9b3ae706820.png)\n",
        "\n",
        "<br/>\n",
        "* Once the assigned memory positions are filled, we have to wait for the other tasks (\\_\\_syncthreads())\n",
        "* Now, we have to calculate the convolution between the system mask and the assigned memory position in the signal vector.\n",
        "\n",
        "You have to implement the algorithms in the following cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "dgy1NBTzdGRA"
      },
      "outputs": [],
      "source": [
        "#example of a convolution operation of a 3x3 matrix with a 1x1 matrix\n",
        "convolution_src = \"\"\"\n",
        "\n",
        "//declare variables needed for convolution operation\n",
        "__global__ void convolution( float *v, \n",
        "                             float *c, \n",
        "                             float *conv,\n",
        "                             int N,\n",
        "                             int c_size){\n",
        "                           \n",
        "//declare a tile and mask memory to be shared across all threads\n",
        "  __shared__ float tile[ HERE SHOULD INDICATES THE STRIDE LENGTH ];\n",
        "  __shared__ float mask[ HERE SHOULD INDICATES THE MASK LENGTH ]\n",
        "\n",
        "  unsigned int t = threadIdx.x; //assign the threadIdx.x value to t, then increment it by 1\n",
        "\n",
        "  //fill the tile memory with tiles \n",
        "  __syncthreads();\n",
        "\n",
        "  float accu = 0;\n",
        "\n",
        "  __syncthreads();\n",
        "  c[blockIdx.x] = accu; //store the value of blockIdx.x in the variable accu \n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "convolution_tmp = \"\"\"\n",
        "__global__ void convolution( float *v, \n",
        "                             float *c, \n",
        "                             float *conv,\n",
        "                             int N,\n",
        "                             int c_size){\n",
        "\n",
        "//declare variables title size and mask size \n",
        "//tile: array of float values to store the output of each thread in a block\n",
        "//mask: array of float values to calculate which pixels should have their value set to 0\n",
        "  __shared__ float tile[ %(TILE_SIZE)s ];\n",
        "  __shared__ float mask[ %(MASK_SIZE)s ];\n",
        "\n",
        "//declare variables t, start, offset\n",
        "//t: integer representing the thread index\n",
        "//start: integer representing the block index\n",
        "//offset: specifies where each tile should be stored, based on its position relative to other tiles\n",
        "  unsigned int t = threadIdx.x; // store the value of threadIdx.x in t (index of the current thread)\n",
        "  unsigned int start = blockIdx.x * blockDim.x;\n",
        "  unsigned int offset = %(MASK_SIZE)s / 2;\n",
        "\n",
        "//check if there is enough space left on either side of t to calculate tiles for both blocks at the same time\n",
        "//iterate through all tiles in the array and set each tile's value to either 0.0 or v[start + t]\n",
        "  if (start + t < N) {\n",
        "    tile[t + offset] = v[start + t];\n",
        "    //if there isn't, then only one block can be calculated at a time \n",
        "  } else { \n",
        "    tile[t + offset] = 0.0;\n",
        "  }\n",
        "\n",
        "\n",
        "  // analyzing beginning of the vector\n",
        "  if (t < offset)\n",
        "    if (blockIdx.x > 0)\n",
        "      tile[t] = v[start+t-2]; // if t==0, we will fetch memory position start-2, if t==1, we will fetch position start-1\n",
        "    else\n",
        "      tile[t] = 0.0;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  // analyzing the end of the vector\n",
        "  if (t > (blockDim.x - offset - 1)){\n",
        "    if ((t + start + offset) < N)\n",
        "      tile[t + offset + offset] = v[start + t + offset];\n",
        "    else\n",
        "      tile[t + offset + offset] = 0.0; // will point to element in next block\n",
        "  }\n",
        "\n",
        "// filling the mask\n",
        "  if ( t < %(MASK_SIZE)s)\n",
        "    mask[t] = conv[t];\n",
        "\n",
        "\n",
        "\n",
        "  //fill the tile memory\n",
        "  //IN THIS SECTION SHOULD FILL THE TILE MEMORY AND MAYBE THE MASK\n",
        "  // all variables in chip memory\n",
        "\n",
        "  __syncthreads();\n",
        "  // calculate the convolution\n",
        "  if ((start + t) < N) {\n",
        "    float accu = 0;\n",
        "    c[start+t] = accu;\n",
        "  }\n",
        "  \n",
        "  __syncthreads();\n",
        " // c[blockIdx.x] = accu;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J3pI0B1C5hcG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "LnbOMgKbh-d_"
      },
      "outputs": [],
      "source": [
        "#create a filter mask on the CPU and then compiles it to a GPU-friendly data type\n",
        "filtermask = np.array([1,1,3,1,1],dtype = np.float32)\n",
        "#prints: [1. 1. 3. 1. 1.]\n",
        "filtermask_gpu = gpuarray.to_gpu(filtermask) #converts filtermask to a GPU array object\n",
        "#prints: [1. 1. 3. 1. 1.]\n",
        "filtermask_size = np.int32(5)\n",
        "#prints: 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "vuIoKeBagf6t"
      },
      "outputs": [],
      "source": [
        "convolved_gpu = gpuarray.empty((datasize,1),np.float32) #create a new GPU array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ECUSD4sFgXi0"
      },
      "outputs": [],
      "source": [
        "#create a 256x256 tile map with 5 tiles per block\n",
        "BLOCKSIZE = 256\n",
        "MASK_SIZE = 5\n",
        "TILE_SIZE = BLOCK_SIZE + MASK_SIZE - 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a convolution kernel that is the same size as the input image\n",
        "convolution_src = convolution_tmp%{\n",
        "'TILE_SIZE': BLOCK_SIZE,\n",
        "'MASK_SIZE': MASK_SIZE,\n",
        "}"
      ],
      "metadata": {
        "id": "87Y3V56R3938"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "N9CcLnVHhehn"
      },
      "outputs": [],
      "source": [
        "#create a convolution_src module, i.e. the first step in creating an image\n",
        "mod2 = SourceModule(convolution_src)\n",
        "\n",
        "#this line kept failing bc it stated that \"identifier accu is undefined, altough it is defined in the previous code snippet\"\n",
        "#issue solved by commenting out  // c[blockIdx.x] = accu; at the bottom of convolution_tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ofnlEJM8hOzo"
      },
      "outputs": [],
      "source": [
        "convolution = mod2.get_function(\"convolution\") #important to remember that it is mod2 now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "648mfVtPi2Ii"
      },
      "outputs": [],
      "source": [
        "n = np.int32(1000000)\n",
        "\n",
        "#define block_size (this is NOT a definition for grid_size!!)\n",
        "block_size = (BLOCK_SIZE,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data type if necessary \n",
        "#type(BLOCK_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-i1SFXlU_gZ",
        "outputId": "34f31465-cdb2-49ac-dbbd-dfcebec7f4c4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "G5BCiVXci9rY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a01d52e-8c39-4c81-d1f6-5fae8ff008f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#calculate the number of blocks & the gridsize\n",
        "numblocks = np.int(np.ceil(n/BLOCK_SIZE))\n",
        "grid_size = (numblocks,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data type if necessary \n",
        "#type(numblocks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GPvsR1GVThN",
        "outputId": "41d7af02-6788-4ec2-b80d-c107c81c524f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "EFX4ji9dhG2d"
      },
      "outputs": [],
      "source": [
        "#compute the convolution operation on a GPU by computing the convolved_gpu matrix with data_gpu & then applying a filter to it (filtermask_gpu)\n",
        "start_t = time.time()\n",
        "convolution(data_gpu,\n",
        "            convolved_gpu,\n",
        "            filtermask_gpu,\n",
        "            n,\n",
        "            filtermask_size,\n",
        "            grid=grid_size,\n",
        "            block=block_size)\n",
        "end_t = time.time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "XoQT98dqjKkP"
      },
      "outputs": [],
      "source": [
        "#take the data and filter it with the filter mask\n",
        "local_convolved = np.convolve(data,filtermask,mode='full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "LwMLSL4njKVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e19ec10-9389-478d-af17-637a377bd403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ],
      "source": [
        "convolved = convolved_gpu.get()\n",
        "print(convolved)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "Tiling is helpful to partition the data into subsets (tiles) so that each tile can fit into the shared memory. We do this because when using CUDA device memories there is a tradeoff: large but slow global memory, and small but fast shared memory. We solve this by partitioning the data to reduce memory traffic. \n",
        "\n",
        "It is crucial to be aware of the data sizes, block sizes, grid sizes, and the element types in each of these arrays. If they are not correctly set, it will not compile correctly. "
      ],
      "metadata": {
        "id": "DEFAlrM1zHh0"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}