{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP7FuserO7nO"
      },
      "source": [
        "# Comparision between classical Matrix Multiplication Algorithm and Tiled Matrix Multiplication\n",
        "\n",
        "In this practical work we will compare these two algorithms, and check how the memory access impacts in the performance.\n",
        "\n",
        "**Authors of the homework:**\n",
        "+ Mireia Izquierdo\n",
        "+ Aleksandra Jamróz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmBjfAoBVsKr"
      },
      "source": [
        "These 2 cells will help us to know which hardware we have assigned, to decide the block size in our parallel algorithm.\n",
        "\n",
        "Sometimes the 256 threads per block (16x16 threads) are the best compromise solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "neJamrihGmPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014d5c22-ae01-49c7-c1cb-2feffe13ecc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 6.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.12.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.9.0)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.1-cp37-cp37m-linux_x86_64.whl size=629701 sha256=d43abd1a8a3c3a9902e6837347f18de002ba24bfe7fe1d656f2a0d313242f7b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/53/c9/caa05618e686df51f017d8a9923f38d915ce31df67ab6628e6\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.12-py2.py3-none-any.whl size=65034 sha256=491b40c619e67bb2e99a92a27bafe6437679b52ab0ba9287c108cb76955b7648\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/5e/9e/76d7430e116b7cab0016fbabb26b896daae1946a3f7dea9915\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: platformdirs, pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.3 platformdirs-2.5.2 pycuda-2022.1 pytools-2022.1.12\n"
          ]
        }
      ],
      "source": [
        "#Check that runtime type is set to GPU !!\n",
        "#Uncomment the follow line if you are running in Google Colaboratory\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aH8z7V4sGzJx"
      },
      "outputs": [],
      "source": [
        "#Import the necessary modules, such as pycuda, numpy and time.\n",
        "import  numpy  as  np  \n",
        "import  pycuda.autoinit #Contains all functions that are automatically imported when using pycuda\n",
        "from    pycuda.compiler import SourceModule\n",
        "import  pycuda.driver as  drv #Python wrapper for CUDA\n",
        "import  pycuda.gpuarray as  gpuarray\n",
        "import  pycuda.tools as gtools\n",
        "from numpy import linalg as la #NumPy linear algebra functions\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mDwt5WwYniI"
      },
      "source": [
        "# FIRST KERNEL: simple matrices multiplication\n",
        "This kernel will recieve 3 matrices: a and b are the source matrices, and c is where we will store the result.\n",
        "\n",
        "The size of the matrix a is $m *n$.\n",
        "\n",
        "The size of the matrix b is $n * o$.\n",
        "\n",
        "The size of the matrix c is $m * o$.\n",
        "\n",
        "All three matrices are stored in a row-wise vector. \n",
        "\n",
        "Each thread will have assigned one cell position in the matrix c. The formulae for both coordinates are:\n",
        "\n",
        "\n",
        "$idxY = blockIdx.y*blockDim.y+threadIdx.y$\n",
        "\n",
        "$idxX = blockIdx.x*blockDim.x+threadIdx.x$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rAyzw3qiG3sb"
      },
      "outputs": [],
      "source": [
        "kernel  =  SourceModule (\"\"\"\n",
        "__global__ void matrix_mult(float* a, \n",
        "                            float* b, \n",
        "                            float* c, \n",
        "                            int m, \n",
        "                            int n, \n",
        "                            int o) \n",
        "{ \n",
        "  // a: vector which represents the matrix_a\n",
        "  // b: vector which represents the matrix_b\n",
        "  // c: vector where we will store the resulting matrix\n",
        "  // m: number of rows of matrix a\n",
        "  // n: number of columns of matrix a, and number of rows of matrix b\n",
        "  // o: number of columns of matrix b\n",
        "\n",
        "  // First task: Using threadIdx.x, threadIdx.y, blockDim.x, blockDim.y, blockIdx.x, blockDim.y identify the coordinates x and y in the result matrix\n",
        "  // Implement the matrix multiplication (cell by cell) using the conventional code.\n",
        "\n",
        "  int idxX;\n",
        "  int idxY;\n",
        "  int idxZ;\n",
        "  int offA;\n",
        "\n",
        "  float s;\n",
        "\n",
        "  idxY = blockIdx.y * blockDim.y + threadIdx.y; //Calculate the row address in target matrix\n",
        "  idxX = blockIdx.x * blockDim.x + threadIdx.x; //Calculate the column address in target matrix\n",
        "\n",
        "\n",
        "  if ( idxX < o && idxY < m ){    //Verify the row address and column address are valid\n",
        "    idxZ = idxY*o + idxX;         //Calculate the target vector address, \n",
        "                                  //Assuming it is a row-wise matrix representation\n",
        "    s = 0;                        //Initialize the s acumulator\n",
        "\n",
        "    offA = idxY * n;                //Calculate the offset of row, in matrix a row-wise representation\n",
        "                                   //Reduce the number of calculae in the next for loop\n",
        "\n",
        "    for ( int i = 0; i<n; i++)     //Run through the a columns, b rows\n",
        "      s += a[offA+i] * b[(i*o) + idxX];\n",
        "    \n",
        "    c[idxZ] = s;\n",
        "  }\n",
        "  \n",
        "}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9pycG9EPHGzY"
      },
      "outputs": [],
      "source": [
        "#Get the CUDA function matrix_mult and assign a Python reference.\n",
        "matrix_mult = kernel.get_function(\"matrix_mult\")\n",
        "\n",
        "#print matrix_mult\n",
        "#print(matrix_mult)\n",
        "#output: <pycuda._driver.Function object at 0x7fd8313a4f80>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7njm6KUZ9o3"
      },
      "source": [
        "For the first case, we creates 3 matrices of size 1024 * 1024 (this is for a fair play comparation with the tiled matrix multiplication)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V24n9UCsa2H6"
      },
      "outputs": [],
      "source": [
        "#define the number of rows and columns for matrix A and B (i.e. the sizes of matrices A and B)\n",
        "#we choose size 1024 * 1024 for a fair comparision with the tiled matrix multiplication\n",
        "numRowsA = 1024\n",
        "numColsA = 1024\n",
        "numRowsB = 1024\n",
        "numColsB = 1024\n",
        "\n",
        "#Create 3 matrices. A and B are filled with random numbers, C is filled with 0s\n",
        "matrix_a = np.random.randn(numRowsA,numColsA).astype(np.float32)\n",
        "matrix_b = np.random.randn(numRowsB,numColsB).astype(np.float32)\n",
        "matrix_c = np.zeros((numRowsA,numColsB),dtype = np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nBQrVcZtHTOk"
      },
      "outputs": [],
      "source": [
        "#Upload the matrices to the GPU, i.e. compile the matrices into GPU arrays\n",
        "matrix_a_gpu = gpuarray.to_gpu(matrix_a)\n",
        "matrix_b_gpu = gpuarray.to_gpu(matrix_b)\n",
        "matrix_c_gpu = gpuarray.to_gpu(matrix_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65alV0m8aKHS"
      },
      "source": [
        "Most GPUs have a multiple core number of 256. This allow us to have the maximum number of blox in execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kxm2nOdbHsIE"
      },
      "outputs": [],
      "source": [
        "#Define a block execution size of 16x16x1 threads. It will allocate 256 threads per block < 1024 (the most common maximum threads/block)\n",
        "block_size = (16,16,1) #We take this value to get up to 256 parallel threads per block \n",
        "                     #This will allow us to get up to 9 parallel blocks in execution in a K80\n",
        "                     #10 parallel blocks in execution in a T4\n",
        "                     #14 parallel blocks in execition in a GTX 1080 Ti\n",
        "                     #17 parallel blocks in execition in a RTX 2080 Ti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dddaiUJeHun9"
      },
      "outputs": [],
      "source": [
        "#Calculate the number of blocks needed in the x and y axis\n",
        "numblocks_x = int(np.ceil(numColsB/16)) \n",
        "numblocks_y = int(np.ceil(numRowsA/16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ktsa4_J-Hx4d"
      },
      "outputs": [],
      "source": [
        "#Define the grid size\n",
        "grid_size = (numblocks_x,numblocks_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8jgeWyPdH07s"
      },
      "outputs": [],
      "source": [
        "#Execute the matrices multiplication algorithm & calculate how long it takes to run\n",
        "start_t = time.time()\n",
        "matrix_mult(matrix_a_gpu,\n",
        "            matrix_b_gpu,\n",
        "            matrix_c_gpu,\n",
        "            np.int32(numRowsA),\n",
        "            np.int32(numColsA),\n",
        "            np.int32(numColsB),\n",
        "            block = block_size,\n",
        "            grid = (numblocks_x,numblocks_y))\n",
        "end_t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iHoQIDAkTvA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc26d765-d66e-4da1-ba4d-3dc1f5908358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time processing: 0.002038240432739258 seconds\n"
          ]
        }
      ],
      "source": [
        "#Calculate how long it took to run\n",
        "print(\"Time processing: {0} seconds\".format(end_t-start_t))\n",
        "#Time processing: 0.0021321773529052734 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4d1vBPYYIoHg"
      },
      "outputs": [],
      "source": [
        "#Get the C result matrix to compare it with the locally computed result\n",
        "matrix_c_final = matrix_c_gpu.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "o716_8FeQajS"
      },
      "outputs": [],
      "source": [
        "#multiply matrix a with matrix b\n",
        "d = np.matmul(matrix_a,matrix_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xH54kWgeVwIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c7776c-5ba0-4973-b9a5-5fd3a4ec6367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: 3.501988699028402e-10\n"
          ]
        }
      ],
      "source": [
        "#compute and print the MSE\n",
        "MSE = np.sum(np.sum(np.power(matrix_c_final-d,2)))/(d.shape[0]*d.shape[1])\n",
        "print(\"Mean Square Error: {0}\".format(MSE))\n",
        "#Mean Square Error: 3.1641275710647676e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "46iD5OWP1pIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dd146b-a91a-460b-925b-969555d812fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019162565"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#Returns the norm of the matrix \n",
        "la.norm(matrix_c_final - d)\n",
        "#output: 0.018214824"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GKyOs2VLTkpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a99776ac-fbf9-49da-e885-8d7ed7f19184"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-19.214125  ,  28.685335  ,   2.4757004 ,  13.44657   ,\n",
              "          6.88626   ,  15.903372  ,   0.91665703,  21.422142  ,\n",
              "         39.52686   ],\n",
              "       [-28.007004  ,  -2.9562702 ,  28.780758  , -66.84069   ,\n",
              "        -27.194145  ,   3.9199438 ,  21.470493  ,  23.766273  ,\n",
              "        -34.02734   ],\n",
              "       [-43.53081   ,  25.132624  ,  38.90423   ,  53.428616  ,\n",
              "         -8.998992  ,  21.043875  ,  -6.9387746 ,  57.83198   ,\n",
              "         37.003414  ],\n",
              "       [-55.544216  ,   7.955236  ,  -3.6870196 ,  27.92066   ,\n",
              "        -13.283571  , -30.683647  , -55.629448  ,  20.763615  ,\n",
              "         -3.9933147 ],\n",
              "       [ -3.5327082 ,  30.961285  ,  22.20616   , -20.47816   ,\n",
              "        -14.204374  , -48.756508  ,  29.608973  ,  36.26625   ,\n",
              "          4.3091226 ],\n",
              "       [-32.4318    ,  85.255684  , -20.408857  ,   6.906548  ,\n",
              "          2.591298  ,   5.0773463 ,  10.055532  , -20.074034  ,\n",
              "        -44.83915   ],\n",
              "       [-48.336933  , -11.225642  ,  44.524017  , -18.938278  ,\n",
              "         62.335537  ,  11.158186  , -32.209488  , -41.667877  ,\n",
              "         -9.436598  ],\n",
              "       [  3.9779158 ,  32.17322   ,  51.308815  ,  13.577982  ,\n",
              "         49.330284  ,   7.8177676 ,  11.169836  ,  40.472946  ,\n",
              "          6.8560333 ],\n",
              "       [ 26.809584  , -31.33399   ,  31.909332  ,  23.72022   ,\n",
              "         23.067905  ,  14.095021  ,  17.543783  ,  31.603075  ,\n",
              "        -28.002344  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "matrix_c_final[290:299,90:99]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f1SsQk1wTrNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7173e2eb-e628-405c-fc4b-2f01a7169f17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-19.214117  ,  28.685352  ,   2.4757013 ,  13.446564  ,\n",
              "          6.88624   ,  15.903359  ,   0.91666627,  21.42212   ,\n",
              "         39.526848  ],\n",
              "       [-28.00703   ,  -2.9562678 ,  28.780758  , -66.84068   ,\n",
              "        -27.19414   ,   3.9199324 ,  21.470488  ,  23.766273  ,\n",
              "        -34.02735   ],\n",
              "       [-43.53081   ,  25.13264   ,  38.904217  ,  53.42858   ,\n",
              "         -8.999003  ,  21.043861  ,  -6.9387646 ,  57.832     ,\n",
              "         37.003384  ],\n",
              "       [-55.544216  ,   7.9552298 ,  -3.6869965 ,  27.920687  ,\n",
              "        -13.283572  , -30.683653  , -55.629467  ,  20.763641  ,\n",
              "         -3.993318  ],\n",
              "       [ -3.5326986 ,  30.961262  ,  22.20615   , -20.478157  ,\n",
              "        -14.204379  , -48.756496  ,  29.608967  ,  36.266235  ,\n",
              "          4.3091245 ],\n",
              "       [-32.431797  ,  85.25569   , -20.40885   ,   6.906542  ,\n",
              "          2.5912971 ,   5.0773535 ,  10.055547  , -20.074045  ,\n",
              "        -44.83918   ],\n",
              "       [-48.336952  , -11.225642  ,  44.524033  , -18.938276  ,\n",
              "         62.335533  ,  11.158197  , -32.209484  , -41.667892  ,\n",
              "         -9.436594  ],\n",
              "       [  3.9779096 ,  32.173225  ,  51.308807  ,  13.577982  ,\n",
              "         49.330276  ,   7.8177633 ,  11.169827  ,  40.472992  ,\n",
              "          6.8560367 ],\n",
              "       [ 26.809576  , -31.33399   ,  31.90933   ,  23.720257  ,\n",
              "         23.067898  ,  14.095011  ,  17.543789  ,  31.603104  ,\n",
              "        -28.002346  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "d[290:299,90:99]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VgrfmqfqRp"
      },
      "source": [
        "# Analysis\n",
        "The Problem with the previous code is the memory access is no coalesced.<br>\n",
        "\n",
        "![image.png](attachment:f31c927a-80fe-4bd4-90ac-074ff2f0f00a.png)\n",
        "\n",
        "\n",
        "So, there is an algorithm which allows an smart memory handling, using the shared memory tiling: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AwE5Pgsdr7pv"
      },
      "outputs": [],
      "source": [
        "kernel_code_template = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *A, float *B, float *C)\n",
        "{\n",
        "\n",
        "  const uint wA = %(MATRIX_A_SIZE)s;\n",
        "  const uint wB = %(MATRIX_B_SIZE)s;  \n",
        "\n",
        "  // Block index\n",
        "  const uint bx = blockIdx.x;\n",
        "  const uint by = blockIdx.y;\n",
        "\n",
        "  // Thread index\n",
        "  const uint tx = threadIdx.x;\n",
        "  const uint ty = threadIdx.y;\n",
        "\n",
        "  // Index of the first sub-matrix of A processed by the block const uint aBegin = wA * %(BLOCK_SIZE)s * by;\n",
        "  // Index of the last sub-matrix of A processed by the block const uint aEnd = aBegin + wA - 1;\n",
        "  // Step size used to iterate through the sub-matrices of A const uint aStep = %(BLOCK_SIZE)s;\n",
        "\n",
        "  // Index of the first sub-matrix of B processed by the block const uint bBegin = %(BLOCK_SIZE)s * bx;\n",
        "  // Step size used to iterate through the sub-matrices of B const uint bStep = %(BLOCK_SIZE)s * wB;\n",
        "\n",
        "  // The element of the block sub-matrix that is computed by the thread\n",
        "  float Csub = 0;\n",
        "\n",
        "  // Loop over all the sub-matrices of A and B required to compute the block sub-matrix\n",
        "  for (int a = aBegin, b = bBegin;\n",
        "       a <= aEnd;\n",
        "       a += aStep, b += bStep) \n",
        "    {\n",
        "      // Shared memory for the sub-matrix of A\n",
        "      __shared__ float As[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "      // Shared memory for the sub-matrix of B\n",
        "      __shared__ float Bs[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "\n",
        "      // Load the matrices from global memory to shared memory. Each thread loads one element of each matrix\n",
        "      As[ty][tx] = A[a + wA * ty + tx];\n",
        "      Bs[ty][tx] = B[b + wB * ty + tx];\n",
        "      \n",
        "      // Sync to make sure the matrices are loaded\n",
        "      __syncthreads();\n",
        "\n",
        "      // Multiply the two matrices together; each thread computes one element of the block sub-matrix\n",
        "      for (int k = 0; k < %(BLOCK_SIZE)s; ++k)\n",
        "        Csub += As[ty][k] * Bs[k][tx];\n",
        "\n",
        "      // Sync to make sure that the preceding computation is done before loading two new sub-matrices of A and B in the next iteration\n",
        "      __syncthreads();\n",
        "    }\n",
        "\n",
        "  // Write the block sub-matrix to global memory. Each thread writes one element const uint c = wB * %(BLOCK_SIZE)s * by + %(BLOCK_SIZE)s * bx;\n",
        "  C[c + wB * ty + tx] = Csub;\n",
        "}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2mTJppzox_Ke"
      },
      "outputs": [],
      "source": [
        "#Define the (square) matrix size\n",
        "MATRIX_A_SIZE = 1024\n",
        "MATRIX_B_SIZE = 1024\n",
        "\n",
        "#Define size of blocks & tiles sub-matrix (we assume that the block size is same as tile size)\n",
        "TILE_SIZE = 16\n",
        "BLOCK_SIZE = TILE_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEuruFYKeDuB"
      },
      "source": [
        "This is a trick to replace in our original code the constants MATRIX_A_SIZE, MATRIX_B_SIZE and BLOCK_SIZE for their values.\n",
        "\n",
        "It allows us change the matrix sizes without changing the original code.\n",
        "\n",
        "(It is not CUDA trick, it's a Python trick using strings and % parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kDnK1ppeyT_o"
      },
      "outputs": [],
      "source": [
        "#Get the kernel code from the template by specifying the constants MATRIX_A_SIZE, MATRIX_B_SIZE, and BLOCK_SIZE\n",
        "kernel_code = kernel_code_template % { \n",
        "    'MATRIX_A_SIZE': MATRIX_A_SIZE,\n",
        "    'MATRIX_B_SIZE': MATRIX_B_SIZE,\n",
        "    'BLOCK_SIZE': BLOCK_SIZE\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWBmmkcJyW-V"
      },
      "outputs": [],
      "source": [
        "#Compile the kernel code, getting the kernel function reference, in matrixmul.\n",
        "mod = SourceModule(kernel_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hNcCouYwyHDL"
      },
      "outputs": [],
      "source": [
        "#Create two random square matrices\n",
        "a_cpu = matrix_a\n",
        "b_cpu = matrix_b\n",
        "\n",
        "#Compute reference on the CPU to verify GPU computation\n",
        "c_cpu = np.dot(a_cpu, b_cpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aacVIkKT9pyz"
      },
      "source": [
        "Instead of creating a host matrix c with 0s, we can reserve the memory in the GPU. Afterwards we can copy the results from the memory to a new local variable.<br/>\n",
        "This will reduce the amount of data to upload (and thus the time it needs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KBeTT-efyKoP"
      },
      "outputs": [],
      "source": [
        "#Transfer host (CPU) memory to device (GPU) memory \n",
        "a_gpu = gpuarray.to_gpu(a_cpu) \n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "#Create empty GPU array for the result (C = A * B)\n",
        "c_gpu = gpuarray.empty((MATRIX_A_SIZE, MATRIX_B_SIZE), np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk9O5-5-ybPc"
      },
      "outputs": [],
      "source": [
        "#Get the kernel function from the compiled module\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cEU1ZCL49py0"
      },
      "outputs": [],
      "source": [
        "#Define the block size\n",
        "block_size = (int(TILE_SIZE),int(TILE_SIZE),1)\n",
        "\n",
        "#Define the grid size\n",
        "grid_size = (int(np.ceil(MATRIX_A_SIZE/TILE_SIZE)),int(np.ceil(MATRIX_A_SIZE/TILE_SIZE)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLxecMfke1SQ"
      },
      "source": [
        "Invokes the matrices multiplication kernel, and measure the timming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Su5q48JJydTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "aa2c3e49-bcbe-478d-a428-ed78ec351735"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c1045f53b0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Call the kernel on the card\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m matrixmul(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0ma_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'matrixmul' is not defined"
          ]
        }
      ],
      "source": [
        "a = np.int32(1024)\n",
        "b = np.int32(1024)\n",
        "c = np.int32(1024)\n",
        "\n",
        "#Call the kernel on the card\n",
        "start_t = time.time()\n",
        "matrixmul(\n",
        "    # inputs\n",
        "    a_gpu, b_gpu, \n",
        "    # output\n",
        "    c_gpu, \n",
        "    # grid of multiple blocks\n",
        "    grid = grid_size,\n",
        "    # block of multiple threads\n",
        "    block = block_size \n",
        "    )\n",
        "end_t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oYsfK4twr0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822c551f-428d-4529-d8cd-a6c1722295bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time processing: 0.0002009868621826172 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"Time processing: {0} seconds\".format(end_t-start_t))\n",
        "#Time processing: 0.0002009868621826172 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9M4o9k5xTwt"
      },
      "outputs": [],
      "source": [
        "c_cpu_final = c_gpu.get()\n",
        "c_cpu_final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_d = np.matmul(matrix_a,matrix_b)\n",
        "new_d"
      ],
      "metadata": {
        "id": "2tr2nNBgN_pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MxPtqVNfZ40"
      },
      "outputs": [],
      "source": [
        "MSE = np.sum(np.sum(np.power(c_cpu_final-d,2)))/(d.shape[0]*d.shape[1])\n",
        "print(\"Mean Square Error: {0}\".format(MSE))\n",
        "#Mean Square Error: 3.1641275710647676e-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EIiYtHHgVTd"
      },
      "source": [
        "# PRACTICAL WORK:\n",
        "\n",
        "Modify the previous code to recieive any dimensional matrices, and be able to multipy them using tiled memory.\n",
        "\n",
        "Take care about boundaries in the final matrix, and fill with zeroes the memory places where the original matrices are not defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JipRYIAj9py3"
      },
      "outputs": [],
      "source": [
        "kernel_code_various_matrix_mult = \"\"\"\n",
        "__global__ void various_matrix_mult(float *A, float *B, float *C, int m, int n, int o)\n",
        "{\n",
        "\n",
        "// Shared memory for the sub-matrix of A\n",
        "__shared__ float ds_A[%(TILE_SIZE)s][%(TILE_SIZE)s];\n",
        "// Shared memory for the sub-matrix of B\n",
        "__shared__ float ds_B[%(TILE_SIZE)s][%(TILE_SIZE)s];\n",
        "\n",
        "\n",
        "// Thread index\n",
        "const uint tx = threadIdx.x;\n",
        "const uint ty = threadIdx.y;\n",
        "\n",
        "int row = blockIdx.y * %(TILE_SIZE)s + threadIdx.y;\n",
        "int col = blockIdx.x * %(TILE_SIZE)s + threadIdx.x;\n",
        "\n",
        "// The element of the block sub-matrix that is computed by the thread\n",
        "float Csub = 0;\n",
        "\n",
        "for (int l = 0; l < ceil((float)n/%(TILE_SIZE)s) ; ++l) {     //iterate through tiles\n",
        "\n",
        "  // Load the matrices from global memory to shared memory, each thread loads one element of each matrix\n",
        "  // blank spaces filling with zeros:\n",
        "\n",
        "  if (row < m  && l * %(TILE_SIZE)s + tx < n)\n",
        "    ds_A[ty][tx] = A[row *n  + l * %(TILE_SIZE)s + tx];\n",
        "  else\n",
        "    ds_A[ty][tx] = 0.0;\n",
        "\n",
        "  if (l * %(TILE_SIZE)s + ty < n  && col < o)\n",
        "    ds_B[ty][tx] = B[(l * %(TILE_SIZE)s + ty) *o  + col];\n",
        "  else\n",
        "    ds_B[ty][tx] = 0.0;  \n",
        "\n",
        "  // Synchronize to make sure the matrices are loaded\n",
        "  __syncthreads();  \n",
        "\n",
        "  // Multiply the two matrices together; each thread computes one element of the block sub-matrix\n",
        "  for (int k = 0; k < %(TILE_SIZE)s  &&  k < n ; ++k) {\n",
        "      Csub +=  ds_A[ty][k] * ds_B[k][tx];\n",
        "  }\n",
        "\n",
        "  // Synchronize to make sure that the preceding computation is done before loading two new sub-matrices of A and B in the next iteration\n",
        "    __syncthreads();\n",
        "}\n",
        "\n",
        "if (row < m  && col < o)\n",
        "  C[row*o+col] = Csub;\n",
        "\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tile size\n",
        "TILE_SIZE = 16\n",
        "\n",
        "# Get the kernel code from the template by specifying the constant\n",
        "kernel_code = kernel_code_various_matrix_mult % { 'TILE_SIZE': TILE_SIZE }"
      ],
      "metadata": {
        "id": "-liAYLlR5xP3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the kernel code & get the kernel function\n",
        "mod = SourceModule(kernel_code)\n",
        "various_matrix_mult = mod.get_function(\"various_matrix_mult\")"
      ],
      "metadata": {
        "id": "TIFitO6EIRZB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the shape of the matrices\n",
        "m = 1023     #Number of rows of matrix a \n",
        "n = 1025     #Number of columns of matrix a and rows of matrix b\n",
        "o = 1027    #Number of columns of matrix b"
      ],
      "metadata": {
        "id": "DC_OEq7TIUgq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create random input matrices and output matrix, all as dtype float \n",
        "matrix_a = np.random.randn(m,n).astype(np.float32)\n",
        "matrix_b = np.random.randn(n,o).astype(np.float32)\n",
        "matrix_c = np.zeros((m,o),dtype = np.float32)"
      ],
      "metadata": {
        "id": "dnQNfkyTIbkM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transfer host (CPU) memory to device (GPU) memory \n",
        "matrix_a_gpu = gpuarray.to_gpu(matrix_a)\n",
        "matrix_b_gpu = gpuarray.to_gpu(matrix_b)\n",
        "matrix_c_gpu = gpuarray.to_gpu(matrix_c)"
      ],
      "metadata": {
        "id": "agTM2ConIhKi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define block size\n",
        "block_size = (16,16,1) # We take this value to get up to 256 parallel threads per block \n",
        "                     # This will allow us to get up to 9 parallel blocks in execution in a K80\n",
        "                     # 10 parallel blocks in execution in a T4\n",
        "                     # 14 parallel blocks in execition in a GTX 1080 Ti\n",
        "                     # 17 parallel blocks in execition in a RTX 2080 Ti"
      ],
      "metadata": {
        "id": "cj_Q4KAuIjLY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numblocks_x = int(np.ceil(o/16))\n",
        "numblocks_y = int(np.ceil(m/16))\n",
        "grid_size = (numblocks_x, numblocks_y)"
      ],
      "metadata": {
        "id": "Z_QBDoH4IkUY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Invoke the matrix multiplication kernel and count the time it takes to run it\n",
        "start_t = time.time()\n",
        "various_matrix_mult(matrix_a_gpu,\n",
        "                    matrix_b_gpu,\n",
        "                    matrix_c_gpu,\n",
        "                    np.int32(m),\n",
        "                    np.int32(n),\n",
        "                    np.int32(o),\n",
        "                    block = block_size,\n",
        "                    grid = (numblocks_x,numblocks_y))\n",
        "end_t = time.time()"
      ],
      "metadata": {
        "id": "jsI2DbaWInIN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the time it takes to process this\n",
        "print(\"Time processing: {0} seconds\".format(end_t - start_t))"
      ],
      "metadata": {
        "id": "rrLS94SnIsRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4a8efd-f5d1-490f-951b-b3c7c52facc5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time processing: 0.0003409385681152344 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the result matrix from GPU memory\n",
        "c_cpu_final = matrix_c_gpu.get()\n",
        "c_cpu_final"
      ],
      "metadata": {
        "id": "aOs_v-IWIyc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2933712e-4093-4138-adfc-ee7fd9e3bb13"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-19.612833 ,  -9.863956 , -19.060343 , ..., -51.75292  ,\n",
              "        -84.98523  ,  20.660486 ],\n",
              "       [ -1.8771812,   1.1504304, -23.739288 , ..., -49.818176 ,\n",
              "         14.193877 ,  -6.9832363],\n",
              "       [-24.945776 , -51.99384  , -26.073706 , ..., -32.01726  ,\n",
              "         13.040907 ,  -5.4235473],\n",
              "       ...,\n",
              "       [-15.770132 ,  12.6268   ,  23.238705 , ...,  28.151834 ,\n",
              "         51.06493  , -14.744515 ],\n",
              "       [ 15.833657 , -36.64549  ,   7.1878767, ...,  -7.38496  ,\n",
              "          5.566458 ,  -6.062813 ],\n",
              "       [-10.538173 ,  19.447533 , -17.217821 , ...,  24.515432 ,\n",
              "        -10.96253  ,  46.84473  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare matmul with numpy\n",
        "compare_matrix = np.matmul(matrix_a,matrix_b)\n",
        "compare_matrix"
      ],
      "metadata": {
        "id": "sv9-LZGHI14O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f396b43b-9eab-48c8-a6b2-445066916884"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-19.612814 ,  -9.863983 , -19.060352 , ..., -51.752903 ,\n",
              "        -84.98523  ,  20.660473 ],\n",
              "       [ -1.8771677,   1.1504226, -23.739292 , ..., -49.8182   ,\n",
              "         14.193876 ,  -6.983244 ],\n",
              "       [-24.945787 , -51.993904 , -26.073715 , ..., -32.01727  ,\n",
              "         13.04091  ,  -5.4235544],\n",
              "       ...,\n",
              "       [-15.770135 ,  12.626825 ,  23.238697 , ...,  28.151836 ,\n",
              "         51.06491  , -14.744509 ],\n",
              "       [ 15.833665 , -36.645477 ,   7.1878633, ...,  -7.384941 ,\n",
              "          5.566455 ,  -6.0628157],\n",
              "       [-10.538168 ,  19.447529 , -17.217812 , ...,  24.515423 ,\n",
              "        -10.962535 ,  46.84471  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate and print the MSE\n",
        "MSE = np.sum(np.sum(np.power(c_cpu_final-compare_matrix,2)))/(compare_matrix.shape[0] * compare_matrix.shape[1])\n",
        "print(\"Mean Square Error: {0}\".format(MSE))\n",
        "#Mean Square Error: 3.500120241522478e-10"
      ],
      "metadata": {
        "id": "xkIxwZJAI-KS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da1d30a-cdf5-4d8e-97a9-494aea6f0858"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: 3.500120241522478e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Matrix multiplication is a good example of a process that can be performed more efficiently by using parallel computing. \n",
        "\n",
        "By tiling, we can reduce the global memory accesses by taking advantage of the GPU's shared memory. When we partition the data into subsets that fit into the shared memory, we can really exploit the advantaged of memory-level parallelism.\n",
        "\n",
        "This can be clearly seen in the improvement in runtime (efficiency), when comparing the different methods. "
      ],
      "metadata": {
        "id": "gMmy_utUOTZy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}