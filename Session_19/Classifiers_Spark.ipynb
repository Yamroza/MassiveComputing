{"cells":[{"cell_type":"markdown","source":["# **Classification tools in MLLib**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"951562f1-e0df-49ae-8dea-af0f0cb9246b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Homework by \n# Mireia Kesti  NIA: 100406960\n# and\n# Aleksandra Jamr√≥z NIA: 100491363"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b9e94b1-3bb7-4dd4-b947-c9ac465afc8c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["In this session, we are going to work with the [MNIST dataset](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#mnist), a widely used dataset in machine learning for testing classification algorithms. The goal of the problem is automatically classify digit images with 784 (28x28) pixels among the ten possible digits.\n\nWe will start working with a reduced version of this dataset consisting of 60,000 training data and 10,000 test samples. But, after completing this notebook, you can analyze the scalability of the different approaches by using the [large version of the MNIST dataset](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#mnist8m) with 8.100.000 patterns.\n\nIn this notebook we will learn to manage the classification tools avaliable in MLLIB, selecting a linear SVM as example of classifier. The outline of this notebook is:\n\n**1. Data reading and preprocessing**\n\n  a) Loading the training data\n  \n  b) Data analysis\n  \n  c) Data preprocessing: normalization\n  \n  d) Preparing training DF\n  \n  e) Preparing the test DF\n  \n**2. Solving classification problems**\n\n  a) Binary classification with SVMs\n    \n  b) SVM evaluation\n    \n  c) Multiclass SVM\n    \n  d) Cross validation of hyperparameters\n    \n**HOMEWORK: feature selection over Spark**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"92ef16a8-42c3-472a-8ee9-9912961712b7","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## **1. Data reading and preprocessing**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"740e9683-ad72-47eb-8dfd-4e8be07a358b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **1.a) Loading the training data**\n\nTogether with this notebook, you have downloaded two data files:\n* \"mnist\": where you can find the 60.000 training data\n* \"mnist.t\": where there are additional 10.000 test images\n\nLet's start uploading these files to Databricks and let's load the training file to analyze the format of the data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"af083a9a-db51-4b88-a4a6-76f674f7a92d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Load the data file as a DF (you need to have uploaded the file  'mnist' to Databricks)\ntrainFileName = \"/FileStore/tables/mnist\"\ntextDF = sqlContext.read.text(trainFileName)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"81b0c063-c186-4c7c-afe7-f203cc131bbd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Exercise:**\nOnce the data are loaded in the variable textDF:\n1. Show the first 10 lines of the DF\n2. Count the total number of lines in the file (or rows of the DF)\n3. Show the content of the first line"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9c9947e1-8629-45b3-b472-840bb809f6d2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# 1. Show the first 10 lines of the DF\ntextDF.show(10)\n\n# 2. Number of lines\nn_lines = textDF.count()\nprint ( 'Number of lines: ' + str(n_lines) )\n\n# 3. Content of the first line\nline = textDF.first()\nprint ( 'First line content:' )\nprint ( line )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5d71f27-50d8-4751-858a-3267b567637b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+\n|               value|\n+--------------------+\n|5 153:3 154:18 15...|\n|0 128:51 129:159 ...|\n|4 161:67 162:232 ...|\n|1 159:124 160:253...|\n|9 209:55 210:148 ...|\n|2 156:13 157:25 1...|\n|1 125:145 126:255...|\n|3 152:38 153:43 1...|\n|1 153:5 154:63 15...|\n|4 135:189 136:190...|\n+--------------------+\nonly showing top 10 rows\n\nNumber of lines: 60000\nFirst line content:\nRow(value='5 153:3 154:18 155:18 156:18 157:126 158:136 159:175 160:26 161:166 162:255 163:247 164:127 177:30 178:36 179:94 180:154 181:170 182:253 183:253 184:253 185:253 186:253 187:225 188:172 189:253 190:242 191:195 192:64 204:49 205:238 206:253 207:253 208:253 209:253 210:253 211:253 212:253 213:253 214:251 215:93 216:82 217:82 218:56 219:39 232:18 233:219 234:253 235:253 236:253 237:253 238:253 239:198 240:182 241:247 242:241 261:80 262:156 263:107 264:253 265:253 266:205 267:11 269:43 270:154 290:14 291:1 292:154 293:253 294:90 320:139 321:253 322:190 323:2 348:11 349:190 350:253 351:70 377:35 378:241 379:225 380:160 381:108 382:1 406:81 407:240 408:253 409:253 410:119 411:25 435:45 436:186 437:253 438:253 439:150 440:27 464:16 465:93 466:252 467:253 468:187 494:249 495:253 496:249 497:64 519:46 520:130 521:183 522:253 523:253 524:207 525:2 545:39 546:148 547:229 548:253 549:253 550:253 551:250 552:182 571:24 572:114 573:221 574:253 575:253 576:253 577:253 578:201 579:78 597:23 598:66 599:213 600:253 601:253 602:253 603:253 604:198 605:81 606:2 623:18 624:171 625:219 626:253 627:253 628:253 629:253 630:195 631:80 632:9 649:55 650:172 651:226 652:253 653:253 654:253 655:253 656:244 657:133 658:11 677:136 678:253 679:253 680:253 681:212 682:135 683:132 684:16')\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+\n|               value|\n+--------------------+\n|5 153:3 154:18 15...|\n|0 128:51 129:159 ...|\n|4 161:67 162:232 ...|\n|1 159:124 160:253...|\n|9 209:55 210:148 ...|\n|2 156:13 157:25 1...|\n|1 125:145 126:255...|\n|3 152:38 153:43 1...|\n|1 153:5 154:63 15...|\n|4 135:189 136:190...|\n+--------------------+\nonly showing top 10 rows\n\nNumber of lines: 60000\nFirst line content:\nRow(value='5 153:3 154:18 155:18 156:18 157:126 158:136 159:175 160:26 161:166 162:255 163:247 164:127 177:30 178:36 179:94 180:154 181:170 182:253 183:253 184:253 185:253 186:253 187:225 188:172 189:253 190:242 191:195 192:64 204:49 205:238 206:253 207:253 208:253 209:253 210:253 211:253 212:253 213:253 214:251 215:93 216:82 217:82 218:56 219:39 232:18 233:219 234:253 235:253 236:253 237:253 238:253 239:198 240:182 241:247 242:241 261:80 262:156 263:107 264:253 265:253 266:205 267:11 269:43 270:154 290:14 291:1 292:154 293:253 294:90 320:139 321:253 322:190 323:2 348:11 349:190 350:253 351:70 377:35 378:241 379:225 380:160 381:108 382:1 406:81 407:240 408:253 409:253 410:119 411:25 435:45 436:186 437:253 438:253 439:150 440:27 464:16 465:93 466:252 467:253 468:187 494:249 495:253 496:249 497:64 519:46 520:130 521:183 522:253 523:253 524:207 525:2 545:39 546:148 547:229 548:253 549:253 550:253 551:250 552:182 571:24 572:114 573:221 574:253 575:253 576:253 577:253 578:201 579:78 597:23 598:66 599:213 600:253 601:253 602:253 603:253 604:198 605:81 606:2 623:18 624:171 625:219 626:253 627:253 628:253 629:253 630:195 631:80 632:9 649:55 650:172 651:226 652:253 653:253 654:253 655:253 656:244 657:133 658:11 677:136 678:253 679:253 680:253 681:212 682:135 683:132 684:16')\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n+--------------------+\n|               value|\n+--------------------+\n|5 153:3 154:18 15...|\n|0 128:51 129:159 ...|\n|4 161:67 162:232 ...|\n|1 159:124 160:253...|\n|9 209:55 210:148 ...|\n|2 156:13 157:25 1...|\n|1 125:145 126:255...|\n|3 152:38 153:43 1...|\n|1 153:5 154:63 15...|\n|4 135:189 136:190...|\n+--------------------+\nonly showing top 10 rows\n\nNumber of lines: 60000\nFirst line content:\nRow(value=u'5 153:3 154:18 155:18 156:18 157:126 158:136 159:175 160:26 161:166 162:255 163:247 164:127 177:30 178:36 179:94 180:154 181:170 182:253 183:253 184:253 185:253 186:253 187:225 188:172 189:253 190:242 191:195 192:64 204:49 205:238 206:253 207:253 208:253 209:253 210:253 211:253 212:253 213:253 214:251 215:93 216:82 217:82 218:56 219:39 232:18 233:219 234:253 235:253 236:253 237:253 238:253 239:198 240:182 241:247 242:241 261:80 262:156 263:107 264:253 265:253 266:205 267:11 269:43 270:154 290:14 291:1 292:154 293:253 294:90 320:139 321:253 322:190 323:2 348:11 349:190 350:253 351:70 377:35 378:241 379:225 380:160 381:108 382:1 406:81 407:240 408:253 409:253 410:119 411:25 435:45 436:186 437:253 438:253 439:150 440:27 464:16 465:93 466:252 467:253 468:187 494:249 495:253 496:249 497:64 519:46 520:130 521:183 522:253 523:253 524:207 525:2 545:39 546:148 547:229 548:253 549:253 550:253 551:250 552:182 571:24 572:114 573:221 574:253 575:253 576:253 577:253 578:201 579:78 597:23 598:66 599:213 600:253 601:253 602:253 603:253 604:198 605:81 606:2 623:18 624:171 625:219 626:253 627:253 628:253 629:253 630:195 631:80 632:9 649:55 650:172 651:226 652:253 653:253 654:253 655:253 656:244 657:133 658:11 677:136 678:253 679:253 680:253 681:212 682:135 683:132 684:16')\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9dae2e5d-885e-43a3-938b-c46a75f79f0c","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["If you analyze the content of the first line, you can check that the labels and the variables are mixed. And, in addition, the variables appear in a sparse format. This data format (known as LIBSVM format) is very common in practice to store [labeled sparse data](https://spark.apache.org/docs/2.2.0/mllib-data-types.html#labeled-point). In fact, this is a text format in which each line represents a labeled sparse feature vector using the following convention:\n\n    label index1:value1 index2:value2 ...\nwhere the indices are one-based and in ascending order. \n\nBy luck, MLLIB includes a specific funtion [spark.read.format(\"libsvm\")](https://spark.apache.org/docs/latest/sql-programming-guide.html#manually-specifying-options) which directly reads this format data file and returns a DF with two columns: \"label\" and \"features\". Besides, the features are saved in a pyspark.ml.linalg.SparseVector. \n\n  *A sparse vector is backed by two parallel arrays: indices and values. For example, a vector (1.0, 0.0, 3.0) can be represented in sparse format as (3, [0, 2], [1.0, 3.0]), where 3 is the size of the vector.*\n\nRun the next cell to load the datafile with the spark.read.format(\"libsvm\") function.\n\n*Note:* To load the data, we have indicated with the option \"numFeatures\" that the total number of pixels is 784. This is useful when some pixels may not present in certain files (because there are always zero), avoiding inconsistent dimensions."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21be89c8-65a2-4c97-8956-580e23c33f0d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["trainFileName = \"/FileStore/tables/mnist\"\ndataDF = spark.read.format(\"libsvm\").option(\"numFeatures\", \"784\").load(trainFileName)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d92986d6-e192-4b88-8166-6bb476843fd1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["** Exercise:**\nUsing the structured DF \"dataDF\", analyze again:\n1. The content of the first 5 lines of the DF\n2. Count the total number of lines in the file (or rows of the DF)\n3. Show the content of the first line: extracting separately the label and the features. What data type is used to store the features?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da427bf4-813a-4508-bc5b-e9eb1ba12bcb","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# 1. Show the first 10 lines of the DF\ntextDF.show(10)\n# 2. Number of lines\nn_lines = dataDF.count()\nprint('Number of lines: ' + str(n_lines))\n# 3. Content of the first line: extrating the label and the features\nline = dataDF.first()\nprint( 'Label: %d'.format(line.label) )\nprint( 'Features:' )\nprint( line[\"features\"] )\n# Feature data type\nprint(type(line[\"features\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"86e0f2f8-b57d-48a7-8174-8c967592d895","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+\n|               value|\n+--------------------+\n|5 153:3 154:18 15...|\n|0 128:51 129:159 ...|\n|4 161:67 162:232 ...|\n|1 159:124 160:253...|\n|9 209:55 210:148 ...|\n|2 156:13 157:25 1...|\n|1 125:145 126:255...|\n|3 152:38 153:43 1...|\n|1 153:5 154:63 15...|\n|4 135:189 136:190...|\n+--------------------+\nonly showing top 10 rows\n\nNumber of lines: 60000\nLabel: %d\nFeatures:\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[3.0,18.0,18.0,18.0,126.0,136.0,175.0,26.0,166.0,255.0,247.0,127.0,30.0,36.0,94.0,154.0,170.0,253.0,253.0,253.0,253.0,253.0,225.0,172.0,253.0,242.0,195.0,64.0,49.0,238.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,251.0,93.0,82.0,82.0,56.0,39.0,18.0,219.0,253.0,253.0,253.0,253.0,253.0,198.0,182.0,247.0,241.0,80.0,156.0,107.0,253.0,253.0,205.0,11.0,43.0,154.0,14.0,1.0,154.0,253.0,90.0,139.0,253.0,190.0,2.0,11.0,190.0,253.0,70.0,35.0,241.0,225.0,160.0,108.0,1.0,81.0,240.0,253.0,253.0,119.0,25.0,45.0,186.0,253.0,253.0,150.0,27.0,16.0,93.0,252.0,253.0,187.0,249.0,253.0,249.0,64.0,46.0,130.0,183.0,253.0,253.0,207.0,2.0,39.0,148.0,229.0,253.0,253.0,253.0,250.0,182.0,24.0,114.0,221.0,253.0,253.0,253.0,253.0,201.0,78.0,23.0,66.0,213.0,253.0,253.0,253.0,253.0,198.0,81.0,2.0,18.0,171.0,219.0,253.0,253.0,253.0,253.0,195.0,80.0,9.0,55.0,172.0,226.0,253.0,253.0,253.0,253.0,244.0,133.0,11.0,136.0,253.0,253.0,253.0,212.0,135.0,132.0,16.0])\n<class 'pyspark.ml.linalg.SparseVector'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+\n|               value|\n+--------------------+\n|5 153:3 154:18 15...|\n|0 128:51 129:159 ...|\n|4 161:67 162:232 ...|\n|1 159:124 160:253...|\n|9 209:55 210:148 ...|\n|2 156:13 157:25 1...|\n|1 125:145 126:255...|\n|3 152:38 153:43 1...|\n|1 153:5 154:63 15...|\n|4 135:189 136:190...|\n+--------------------+\nonly showing top 10 rows\n\nNumber of lines: 60000\nLabel: %d\nFeatures:\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[3.0,18.0,18.0,18.0,126.0,136.0,175.0,26.0,166.0,255.0,247.0,127.0,30.0,36.0,94.0,154.0,170.0,253.0,253.0,253.0,253.0,253.0,225.0,172.0,253.0,242.0,195.0,64.0,49.0,238.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,251.0,93.0,82.0,82.0,56.0,39.0,18.0,219.0,253.0,253.0,253.0,253.0,253.0,198.0,182.0,247.0,241.0,80.0,156.0,107.0,253.0,253.0,205.0,11.0,43.0,154.0,14.0,1.0,154.0,253.0,90.0,139.0,253.0,190.0,2.0,11.0,190.0,253.0,70.0,35.0,241.0,225.0,160.0,108.0,1.0,81.0,240.0,253.0,253.0,119.0,25.0,45.0,186.0,253.0,253.0,150.0,27.0,16.0,93.0,252.0,253.0,187.0,249.0,253.0,249.0,64.0,46.0,130.0,183.0,253.0,253.0,207.0,2.0,39.0,148.0,229.0,253.0,253.0,253.0,250.0,182.0,24.0,114.0,221.0,253.0,253.0,253.0,253.0,201.0,78.0,23.0,66.0,213.0,253.0,253.0,253.0,253.0,198.0,81.0,2.0,18.0,171.0,219.0,253.0,253.0,253.0,253.0,195.0,80.0,9.0,55.0,172.0,226.0,253.0,253.0,253.0,253.0,244.0,133.0,11.0,136.0,253.0,253.0,253.0,212.0,135.0,132.0,16.0])\n<class 'pyspark.ml.linalg.SparseVector'>\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  5.0|(784,[152,153,154...|\n|  0.0|(784,[127,128,129...|\n|  4.0|(784,[160,161,162...|\n|  1.0|(784,[158,159,160...|\n|  9.0|(784,[208,209,210...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of lines: 60000\nLabel: 5\nFeatures:\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[3.0,18.0,18.0,18.0,126.0,136.0,175.0,26.0,166.0,255.0,247.0,127.0,30.0,36.0,94.0,154.0,170.0,253.0,253.0,253.0,253.0,253.0,225.0,172.0,253.0,242.0,195.0,64.0,49.0,238.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,251.0,93.0,82.0,82.0,56.0,39.0,18.0,219.0,253.0,253.0,253.0,253.0,253.0,198.0,182.0,247.0,241.0,80.0,156.0,107.0,253.0,253.0,205.0,11.0,43.0,154.0,14.0,1.0,154.0,253.0,90.0,139.0,253.0,190.0,2.0,11.0,190.0,253.0,70.0,35.0,241.0,225.0,160.0,108.0,1.0,81.0,240.0,253.0,253.0,119.0,25.0,45.0,186.0,253.0,253.0,150.0,27.0,16.0,93.0,252.0,253.0,187.0,249.0,253.0,249.0,64.0,46.0,130.0,183.0,253.0,253.0,207.0,2.0,39.0,148.0,229.0,253.0,253.0,253.0,250.0,182.0,24.0,114.0,221.0,253.0,253.0,253.0,253.0,201.0,78.0,23.0,66.0,213.0,253.0,253.0,253.0,253.0,198.0,81.0,2.0,18.0,171.0,219.0,253.0,253.0,253.0,253.0,195.0,80.0,9.0,55.0,172.0,226.0,253.0,253.0,253.0,253.0,244.0,133.0,11.0,136.0,253.0,253.0,253.0,212.0,135.0,132.0,16.0])\nclass 'pyspark.ml.linalg.SparseVector'\n\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2099958b-2e40-4d4e-a71f-a1139ffa833c","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **1.b) Data analysis**\n\nTo analyze in detail the type of data that we are handling, let's draw some of the digit images.\n\n**Exercise:** using the function provided in the next cell, plot the first 10 rows of dataDF."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6042be9d-5c4b-4cea-8cda-01a74de4c452","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nfrom pyspark.mllib.linalg import Vectors\n\ndef plot_data(images, h, w, n_row=1, n_col=10):\n    \"\"\"\n    Plots the set of images provided in images\n\n    Args:\n        images (list of sparse vectors or numpy arrays): list of images where each image contains the \n            features corresponding to the pixels of an image.  \n        h: heigth of the image (in number of pixels).\n        w: width of the image (in number of pixels).\n        n_row: Number of rows to use when plotting all the images\n        n_col: Number of columns to use when plotting all the images\n\n    \"\"\"\n    fig = plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    \n    for i in range(len(images)):\n        plt.subplot(n_row, n_col, i + 1)      \n        try: # In the case each element of \"images\" is a row data with a variable \"features\" \n            img = images[i].features.toArray()\n        except: # In the case each element of \"images\" is directly the pixel values\n            img = images[i]\n            \n        plt.imshow(img.reshape((h, w )), cmap=plt.cm.jet)\n        plt.xticks(())\n        plt.yticks(())\n    return fig"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3b30c8b0-fed8-422a-ace3-bb76a5320d3c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Define the height and width of the images\nh = 28\nw = 28\n\n# Pick up 10 images and plot them using the function  plot_data()\nimages = dataDF.take(10)\nfig = plot_data(images, h, w)\n# display(fig)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"af5dc6d7-9d45-4f89-8060-3a26e7c6a654","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\nfeaturesDF:pyspark.sql.dataframe.DataFrame = [features: udt]\n<img src=\"http://www.tsc.uc3m.es/~vanessa/figsdatabricks/fig_digits.png\"/>\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4cfa2d21-1cab-4066-8b35-b41f01aaf6d1","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **1.c) Data preprocessing: normalization**\n\nIn general, normalization process consists of two steps:\n1. Removing the mean of each feature\n2. Rescaling each feature to make it to have a unit standard deviation\n\nBecause we are working with the sparse data (most of the input characteristics are zero), if we eliminate the mean, we would be converting null values into non-zero values, increasing the size (in memory) of the data set. To avoid this problem, here, we're just going to rescale the data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68d911ed-55c6-4fab-a416-90e8cc3a50e8","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**Exercise:** Complete the following cell to reescale the data by making use of the [StandardScaler()](https://spark.apache.org/docs/2.1.0/ml-features.html#standardscaler) method of MLLIB \n\n*Note:* StandardScaler method has two input variables, 'withMean' and 'withStd', which let you select, respectivelly, whether the mean and standard deviation are corrected or not."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a73628b9-eb5a-4764-b01e-244ee23609c5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.feature import StandardScaler\n\n# Define the normalizer object: indicate that you only want each feature to have unit standard deviation. Use the nomenclature \"normFeatures\" for column with the output normalized features.\nscaler = StandardScaler(inputCol=\"features\", outputCol=\"normFeatures\")\n\n# Fit the StandardScaler: learn the statistics of the data\nscalerModel = scaler.fit(dataDF)\n\n# Normalize the data: apply the normalization transformation\nscaledData = scalerModel.transform(dataDF)\n\n# For the first data: compare the first 10 original features with the normalized ones\nfirstData = scaledData.first()\nprint ( firstData.features )\nprint ( firstData.normFeatures )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"928af9f3-060c-4e52-9775-450323e7fbec","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[3.0,18.0,18.0,18.0,126.0,136.0,175.0,26.0,166.0,255.0,247.0,127.0,30.0,36.0,94.0,154.0,170.0,253.0,253.0,253.0,253.0,253.0,225.0,172.0,253.0,242.0,195.0,64.0,49.0,238.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,251.0,93.0,82.0,82.0,56.0,39.0,18.0,219.0,253.0,253.0,253.0,253.0,253.0,198.0,182.0,247.0,241.0,80.0,156.0,107.0,253.0,253.0,205.0,11.0,43.0,154.0,14.0,1.0,154.0,253.0,90.0,139.0,253.0,190.0,2.0,11.0,190.0,253.0,70.0,35.0,241.0,225.0,160.0,108.0,1.0,81.0,240.0,253.0,253.0,119.0,25.0,45.0,186.0,253.0,253.0,150.0,27.0,16.0,93.0,252.0,253.0,187.0,249.0,253.0,249.0,64.0,46.0,130.0,183.0,253.0,253.0,207.0,2.0,39.0,148.0,229.0,253.0,253.0,253.0,250.0,182.0,24.0,114.0,221.0,253.0,253.0,253.0,253.0,201.0,78.0,23.0,66.0,213.0,253.0,253.0,253.0,253.0,198.0,81.0,2.0,18.0,171.0,219.0,253.0,253.0,253.0,253.0,195.0,80.0,9.0,55.0,172.0,226.0,253.0,253.0,253.0,253.0,244.0,133.0,11.0,136.0,253.0,253.0,253.0,212.0,135.0,132.0,16.0])\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[0.031374699274264506,0.17461879779021092,0.16796228169449112,0.1659028392405828,1.1678132414369087,1.2938845179089489,1.7689104898164847,0.29044539967781535,2.1632873324779034,4.121038488523313,5.1997998744978355,3.640343824366569,0.45157429952347355,0.44707491080672346,1.0173131985418946,1.5175662830621006,1.5781000431417094,2.278875175954822,2.2554561559760304,2.252180252227004,2.252256492429137,2.2558702193596276,2.047866319570414,1.6579874660018918,2.7183550342922755,3.0986636639674123,3.152049964796779,1.3923097152389106,0.7658421810153346,3.0104730424041324,2.7419654131673727,2.486444660246641,2.3541724709075655,2.3009874899408693,2.2914916097068065,2.2909998474440236,2.2974400506953474,2.2952907311901622,2.267921272111156,0.8379804117490846,0.7548366072581753,0.8114156585513068,0.6372066614556388,0.5508906646726361,0.2476908910471118,2.486708535635483,2.5283423086813515,2.3592651710780523,2.2913405393264674,2.27702820036933,2.271724137963616,1.7807758614417155,1.6425668934145574,2.2299332173164816,2.170772337804973,0.8544541072865441,1.4944939655543321,0.9728245186881226,2.270080815920683,2.2724148950660115,1.8617957632542175,0.10094043619238478,0.3933049064364007,1.3931401221605737,0.13165507023515371,0.009061553059047187,1.3902480311438592,2.3431263444486485,0.8647658095874232,1.2773396350413717,2.4313015007527623,1.8976891186418021,0.019461389090040047,0.10167495542063257,1.8272021706491468,2.4551133651463943,0.6427626754183501,0.3290932873035842,2.216763427204788,1.9769095596166009,1.4336057497915133,0.9822845826719797,0.00891668531398235,0.7261248605550772,2.1102955107653676,2.310022172345761,2.303347013422948,1.0589164343226194,0.22507588447239335,0.3995875120020824,1.7013088130935585,2.271977985380326,2.246612480103301,1.3655626316973337,0.2592117268636886,0.14377571657827934,0.8292710685678274,2.2655417706827556,2.3315388008053133,1.7975483600731317,2.2666899527122806,2.3365971977939872,2.385903064382727,0.6615483743982672,0.4137546545780372,1.1716519008331214,1.6606558553284827,2.295724967192719,2.3206452744513597,1.9782366268123184,0.020983924922013165,0.3592604663629126,1.3416445030139248,2.054459322020695,2.2782636510012106,2.287461460113521,2.277364206555067,2.2933442614655757,1.7753981493864393,0.22000788072961186,1.0324334607198007,1.987387666968594,2.2669083265572736,2.269556403538387,2.2748485034929713,2.2743981558166104,1.8188220638701889,0.7321798562686532,0.22266285416973614,0.6063395129056782,1.9165424544013492,2.269879643905871,2.277552434882023,2.2924697675245604,2.2876915463139382,1.7843521435614278,0.7322889102775604,0.018604292330661444,0.277298148027065,2.0468526399028306,2.23566468494158,2.3633555432188147,2.2686430452409376,2.2417853747386443,2.2498768448321447,1.7389839255042636,0.712908786519703,0.08086496577942506,3.1738301505736484,5.776976709945052,4.889879470839611,3.9084160622150175,3.080086515158155,2.643588376937392,2.4196016122106783,2.2354480960783962,1.2031420718203238,0.09981160392855332,14.401680484852115,15.062850898111083,9.245781133463572,6.182033015797069,3.824543443311354,1.9368731569911861,1.6288667102255985,0.18131845184802203])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[3.0,18.0,18.0,18.0,126.0,136.0,175.0,26.0,166.0,255.0,247.0,127.0,30.0,36.0,94.0,154.0,170.0,253.0,253.0,253.0,253.0,253.0,225.0,172.0,253.0,242.0,195.0,64.0,49.0,238.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,251.0,93.0,82.0,82.0,56.0,39.0,18.0,219.0,253.0,253.0,253.0,253.0,253.0,198.0,182.0,247.0,241.0,80.0,156.0,107.0,253.0,253.0,205.0,11.0,43.0,154.0,14.0,1.0,154.0,253.0,90.0,139.0,253.0,190.0,2.0,11.0,190.0,253.0,70.0,35.0,241.0,225.0,160.0,108.0,1.0,81.0,240.0,253.0,253.0,119.0,25.0,45.0,186.0,253.0,253.0,150.0,27.0,16.0,93.0,252.0,253.0,187.0,249.0,253.0,249.0,64.0,46.0,130.0,183.0,253.0,253.0,207.0,2.0,39.0,148.0,229.0,253.0,253.0,253.0,250.0,182.0,24.0,114.0,221.0,253.0,253.0,253.0,253.0,201.0,78.0,23.0,66.0,213.0,253.0,253.0,253.0,253.0,198.0,81.0,2.0,18.0,171.0,219.0,253.0,253.0,253.0,253.0,195.0,80.0,9.0,55.0,172.0,226.0,253.0,253.0,253.0,253.0,244.0,133.0,11.0,136.0,253.0,253.0,253.0,212.0,135.0,132.0,16.0])\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[0.031374699274264506,0.17461879779021092,0.16796228169449112,0.1659028392405828,1.1678132414369087,1.2938845179089489,1.7689104898164847,0.29044539967781535,2.1632873324779034,4.121038488523313,5.1997998744978355,3.640343824366569,0.45157429952347355,0.44707491080672346,1.0173131985418946,1.5175662830621006,1.5781000431417094,2.278875175954822,2.2554561559760304,2.252180252227004,2.252256492429137,2.2558702193596276,2.047866319570414,1.6579874660018918,2.7183550342922755,3.0986636639674123,3.152049964796779,1.3923097152389106,0.7658421810153346,3.0104730424041324,2.7419654131673727,2.486444660246641,2.3541724709075655,2.3009874899408693,2.2914916097068065,2.2909998474440236,2.2974400506953474,2.2952907311901622,2.267921272111156,0.8379804117490846,0.7548366072581753,0.8114156585513068,0.6372066614556388,0.5508906646726361,0.2476908910471118,2.486708535635483,2.5283423086813515,2.3592651710780523,2.2913405393264674,2.27702820036933,2.271724137963616,1.7807758614417155,1.6425668934145574,2.2299332173164816,2.170772337804973,0.8544541072865441,1.4944939655543321,0.9728245186881226,2.270080815920683,2.2724148950660115,1.8617957632542175,0.10094043619238478,0.3933049064364007,1.3931401221605737,0.13165507023515371,0.009061553059047187,1.3902480311438592,2.3431263444486485,0.8647658095874232,1.2773396350413717,2.4313015007527623,1.8976891186418021,0.019461389090040047,0.10167495542063257,1.8272021706491468,2.4551133651463943,0.6427626754183501,0.3290932873035842,2.216763427204788,1.9769095596166009,1.4336057497915133,0.9822845826719797,0.00891668531398235,0.7261248605550772,2.1102955107653676,2.310022172345761,2.303347013422948,1.0589164343226194,0.22507588447239335,0.3995875120020824,1.7013088130935585,2.271977985380326,2.246612480103301,1.3655626316973337,0.2592117268636886,0.14377571657827934,0.8292710685678274,2.2655417706827556,2.3315388008053133,1.7975483600731317,2.2666899527122806,2.3365971977939872,2.385903064382727,0.6615483743982672,0.4137546545780372,1.1716519008331214,1.6606558553284827,2.295724967192719,2.3206452744513597,1.9782366268123184,0.020983924922013165,0.3592604663629126,1.3416445030139248,2.054459322020695,2.2782636510012106,2.287461460113521,2.277364206555067,2.2933442614655757,1.7753981493864393,0.22000788072961186,1.0324334607198007,1.987387666968594,2.2669083265572736,2.269556403538387,2.2748485034929713,2.2743981558166104,1.8188220638701889,0.7321798562686532,0.22266285416973614,0.6063395129056782,1.9165424544013492,2.269879643905871,2.277552434882023,2.2924697675245604,2.2876915463139382,1.7843521435614278,0.7322889102775604,0.018604292330661444,0.277298148027065,2.0468526399028306,2.23566468494158,2.3633555432188147,2.2686430452409376,2.2417853747386443,2.2498768448321447,1.7389839255042636,0.712908786519703,0.08086496577942506,3.1738301505736484,5.776976709945052,4.889879470839611,3.9084160622150175,3.080086515158155,2.643588376937392,2.4196016122106783,2.2354480960783962,1.2031420718203238,0.09981160392855332,14.401680484852115,15.062850898111083,9.245781133463572,6.182033015797069,3.824543443311354,1.9368731569911861,1.6288667102255985,0.18131845184802203])\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n\nscaledData:pyspark.sql.dataframe.DataFrame = [label: double, features: udt ... 1 more fields]\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[3.0,18.0,18.0,18.0,126.0,136.0,175.0,26.0,166.0,255.0,247.0,127.0,30.0,36.0,94.0,154.0,170.0,253.0,253.0,253.0,253.0,253.0,225.0,172.0,253.0,242.0,195.0,64.0,49.0,238.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,253.0,251.0,93.0,82.0,82.0,56.0,39.0,18.0,219.0,253.0,253.0,253.0,253.0,253.0,198.0,182.0,247.0,241.0,80.0,156.0,107.0,253.0,253.0,205.0,11.0,43.0,154.0,14.0,1.0,154.0,253.0,90.0,139.0,253.0,190.0,2.0,11.0,190.0,253.0,70.0,35.0,241.0,225.0,160.0,108.0,1.0,81.0,240.0,253.0,253.0,119.0,25.0,45.0,186.0,253.0,253.0,150.0,27.0,16.0,93.0,252.0,253.0,187.0,249.0,253.0,249.0,64.0,46.0,130.0,183.0,253.0,253.0,207.0,2.0,39.0,148.0,229.0,253.0,253.0,253.0,250.0,182.0,24.0,114.0,221.0,253.0,253.0,253.0,253.0,201.0,78.0,23.0,66.0,213.0,253.0,253.0,253.0,253.0,198.0,81.0,2.0,18.0,171.0,219.0,253.0,253.0,253.0,253.0,195.0,80.0,9.0,55.0,172.0,226.0,253.0,253.0,253.0,253.0,244.0,133.0,11.0,136.0,253.0,253.0,253.0,212.0,135.0,132.0,16.0])\n(784,[152,153,154,155,156,157,158,159,160,161,162,163,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,231,232,233,234,235,236,237,238,239,240,241,260,261,262,263,264,265,266,268,269,289,290,291,292,293,319,320,321,322,347,348,349,350,376,377,378,379,380,381,405,406,407,408,409,410,434,435,436,437,438,439,463,464,465,466,467,493,494,495,496,518,519,520,521,522,523,524,544,545,546,547,548,549,550,551,570,571,572,573,574,575,576,577,578,596,597,598,599,600,601,602,603,604,605,622,623,624,625,626,627,628,629,630,631,648,649,650,651,652,653,654,655,656,657,676,677,678,679,680,681,682,683],[0.0313746992743,0.17461879779,0.167962281694,0.165902839241,1.16781324144,1.29388451791,1.76891048982,0.290445399678,2.16328733248,4.12103848852,5.1997998745,3.64034382437,0.451574299523,0.447074910807,1.01731319854,1.51756628306,1.57810004314,2.27887517595,2.25545615598,2.25218025223,2.25225649243,2.25587021936,2.04786631957,1.657987466,2.71835503429,3.09866366397,3.1520499648,1.39230971524,0.765842181015,3.0104730424,2.74196541317,2.48644466025,2.35417247091,2.30098748994,2.29149160971,2.29099984744,2.2974400507,2.29529073119,2.26792127211,0.837980411749,0.754836607258,0.811415658551,0.637206661456,0.550890664673,0.247690891047,2.48670853564,2.52834230868,2.35926517108,2.29134053933,2.27702820037,2.27172413796,1.78077586144,1.64256689341,2.22993321732,2.1707723378,0.854454107287,1.49449396555,0.972824518688,2.27008081592,2.27241489507,1.86179576325,0.100940436192,0.393304906436,1.39314012216,0.131655070235,0.00906155305905,1.39024803114,2.34312634445,0.864765809587,1.27733963504,2.43130150075,1.89768911864,0.01946138909,0.101674955421,1.82720217065,2.45511336515,0.642762675418,0.329093287304,2.2167634272,1.97690955962,1.43360574979,0.982284582672,0.00891668531398,0.726124860555,2.11029551077,2.31002217235,2.30334701342,1.05891643432,0.225075884472,0.399587512002,1.70130881309,2.27197798538,2.2466124801,1.3655626317,0.259211726864,0.143775716578,0.829271068568,2.26554177068,2.33153880081,1.79754836007,2.26668995271,2.33659719779,2.38590306438,0.661548374398,0.413754654578,1.17165190083,1.66065585533,2.29572496719,2.32064527445,1.97823662681,0.020983924922,0.359260466363,1.34164450301,2.05445932202,2.278263651,2.28746146011,2.27736420656,2.29334426147,1.77539814939,0.22000788073,1.03243346072,1.98738766697,2.26690832656,2.26955640354,2.27484850349,2.27439815582,1.81882206387,0.732179856269,0.22266285417,0.606339512906,1.9165424544,2.26987964391,2.27755243488,2.29246976752,2.28769154631,1.78435214356,0.732288910278,0.0186042923307,0.277298148027,2.0468526399,2.23566468494,2.36335554322,2.26864304524,2.24178537474,2.24987684483,1.7389839255,0.71290878652,0.0808649657794,3.17383015057,5.77697670995,4.88987947084,3.90841606222,3.08008651516,2.64358837694,2.41960161221,2.23544809608,1.20314207182,0.0998116039286,14.4016804849,15.0628508981,9.24578113346,6.1820330158,3.82454344331,1.93687315699,1.62886671023,0.181318451848])\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"072e8767-dd68-4ed2-be7f-1eeb7f405d8d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["When the scalerModel has been trained, we have learned some statistics of the data, such as, the mean value and standard deviation of each pixel. \n\n**Exercise**: extract the mean and standard deviation values from the scalerModel object. Plot these values using the plot_data() function.\n\n*Note:* you can check the object parameters and functions with the command \"help(scalerModel)\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9fe5166-cc3d-4985-ab03-b6d3b8137289","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Analyze the scalerModel object. You can access to the mean and std of the data\nmeanValues = scalerModel.mean\nstdValues= scalerModel.std\n\n# Plot these values\nfig = plot_data([scalerModel.mean,scalerModel.std] , h, w)\n# display(fig)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"57d41656-9d24-4440-b0d0-b104f5313b9a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n<img src=\"http://www.tsc.uc3m.es/~vanessa/figsdatabricks/fig_digits_stats.png\"/>\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cb58c020-6083-40e4-ad06-3e17d1f06aaa","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **1.d) Preparing training DF**\n\nTo finish the preprocessing of the data, let's create the training DF. So that this DF can interact with MLLIB functions, it is required that it has two columns with the following names:\n* \"label\": where the data labels have to be stored.\n* \"features\": where the features, used as input of the classifiers, have to be stored.\n\n** Exercise**: transform the DF \"scaledData\" by selecting their columns \"label\" and \"normFeatures\" and, renaming this last column as \"features\". Call this new DF as \"trainDF\"."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f82262db-9625-4b26-8d6b-9f13ae81635a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Create the training data DF\ntrainDF = scaledData.select(\"label\", scaledData[\"normFeatures\"].alias(\"features\"))\n\n# Examine the resulting DF\ntrainDF.show(5)\ntrainDF.first()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3d44d44a-2edc-48db-899e-9ec91b117ed1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  5.0|(784,[152,153,154...|\n|  0.0|(784,[127,128,129...|\n|  4.0|(784,[160,161,162...|\n|  1.0|(784,[158,159,160...|\n|  9.0|(784,[208,209,210...|\n+-----+--------------------+\nonly showing top 5 rows\n\nOut[14]: Row(label=5.0, features=SparseVector(784, {152: 0.0314, 153: 0.1746, 154: 0.168, 155: 0.1659, 156: 1.1678, 157: 1.2939, 158: 1.7689, 159: 0.2904, 160: 2.1633, 161: 4.121, 162: 5.1998, 163: 3.6403, 176: 0.4516, 177: 0.4471, 178: 1.0173, 179: 1.5176, 180: 1.5781, 181: 2.2789, 182: 2.2555, 183: 2.2522, 184: 2.2523, 185: 2.2559, 186: 2.0479, 187: 1.658, 188: 2.7184, 189: 3.0987, 190: 3.152, 191: 1.3923, 203: 0.7658, 204: 3.0105, 205: 2.742, 206: 2.4864, 207: 2.3542, 208: 2.301, 209: 2.2915, 210: 2.291, 211: 2.2974, 212: 2.2953, 213: 2.2679, 214: 0.838, 215: 0.7548, 216: 0.8114, 217: 0.6372, 218: 0.5509, 231: 0.2477, 232: 2.4867, 233: 2.5283, 234: 2.3593, 235: 2.2913, 236: 2.277, 237: 2.2717, 238: 1.7808, 239: 1.6426, 240: 2.2299, 241: 2.1708, 260: 0.8545, 261: 1.4945, 262: 0.9728, 263: 2.2701, 264: 2.2724, 265: 1.8618, 266: 0.1009, 268: 0.3933, 269: 1.3931, 289: 0.1317, 290: 0.0091, 291: 1.3902, 292: 2.3431, 293: 0.8648, 319: 1.2773, 320: 2.4313, 321: 1.8977, 322: 0.0195, 347: 0.1017, 348: 1.8272, 349: 2.4551, 350: 0.6428, 376: 0.3291, 377: 2.2168, 378: 1.9769, 379: 1.4336, 380: 0.9823, 381: 0.0089, 405: 0.7261, 406: 2.1103, 407: 2.31, 408: 2.3033, 409: 1.0589, 410: 0.2251, 434: 0.3996, 435: 1.7013, 436: 2.272, 437: 2.2466, 438: 1.3656, 439: 0.2592, 463: 0.1438, 464: 0.8293, 465: 2.2655, 466: 2.3315, 467: 1.7975, 493: 2.2667, 494: 2.3366, 495: 2.3859, 496: 0.6615, 518: 0.4138, 519: 1.1717, 520: 1.6607, 521: 2.2957, 522: 2.3206, 523: 1.9782, 524: 0.021, 544: 0.3593, 545: 1.3416, 546: 2.0545, 547: 2.2783, 548: 2.2875, 549: 2.2774, 550: 2.2933, 551: 1.7754, 570: 0.22, 571: 1.0324, 572: 1.9874, 573: 2.2669, 574: 2.2696, 575: 2.2748, 576: 2.2744, 577: 1.8188, 578: 0.7322, 596: 0.2227, 597: 0.6063, 598: 1.9165, 599: 2.2699, 600: 2.2776, 601: 2.2925, 602: 2.2877, 603: 1.7844, 604: 0.7323, 605: 0.0186, 622: 0.2773, 623: 2.0469, 624: 2.2357, 625: 2.3634, 626: 2.2686, 627: 2.2418, 628: 2.2499, 629: 1.739, 630: 0.7129, 631: 0.0809, 648: 3.1738, 649: 5.777, 650: 4.8899, 651: 3.9084, 652: 3.0801, 653: 2.6436, 654: 2.4196, 655: 2.2354, 656: 1.2031, 657: 0.0998, 676: 14.4017, 677: 15.0629, 678: 9.2458, 679: 6.182, 680: 3.8245, 681: 1.9369, 682: 1.6289, 683: 0.1813}))","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  5.0|(784,[152,153,154...|\n|  0.0|(784,[127,128,129...|\n|  4.0|(784,[160,161,162...|\n|  1.0|(784,[158,159,160...|\n|  9.0|(784,[208,209,210...|\n+-----+--------------------+\nonly showing top 5 rows\n\nOut[14]: Row(label=5.0, features=SparseVector(784, {152: 0.0314, 153: 0.1746, 154: 0.168, 155: 0.1659, 156: 1.1678, 157: 1.2939, 158: 1.7689, 159: 0.2904, 160: 2.1633, 161: 4.121, 162: 5.1998, 163: 3.6403, 176: 0.4516, 177: 0.4471, 178: 1.0173, 179: 1.5176, 180: 1.5781, 181: 2.2789, 182: 2.2555, 183: 2.2522, 184: 2.2523, 185: 2.2559, 186: 2.0479, 187: 1.658, 188: 2.7184, 189: 3.0987, 190: 3.152, 191: 1.3923, 203: 0.7658, 204: 3.0105, 205: 2.742, 206: 2.4864, 207: 2.3542, 208: 2.301, 209: 2.2915, 210: 2.291, 211: 2.2974, 212: 2.2953, 213: 2.2679, 214: 0.838, 215: 0.7548, 216: 0.8114, 217: 0.6372, 218: 0.5509, 231: 0.2477, 232: 2.4867, 233: 2.5283, 234: 2.3593, 235: 2.2913, 236: 2.277, 237: 2.2717, 238: 1.7808, 239: 1.6426, 240: 2.2299, 241: 2.1708, 260: 0.8545, 261: 1.4945, 262: 0.9728, 263: 2.2701, 264: 2.2724, 265: 1.8618, 266: 0.1009, 268: 0.3933, 269: 1.3931, 289: 0.1317, 290: 0.0091, 291: 1.3902, 292: 2.3431, 293: 0.8648, 319: 1.2773, 320: 2.4313, 321: 1.8977, 322: 0.0195, 347: 0.1017, 348: 1.8272, 349: 2.4551, 350: 0.6428, 376: 0.3291, 377: 2.2168, 378: 1.9769, 379: 1.4336, 380: 0.9823, 381: 0.0089, 405: 0.7261, 406: 2.1103, 407: 2.31, 408: 2.3033, 409: 1.0589, 410: 0.2251, 434: 0.3996, 435: 1.7013, 436: 2.272, 437: 2.2466, 438: 1.3656, 439: 0.2592, 463: 0.1438, 464: 0.8293, 465: 2.2655, 466: 2.3315, 467: 1.7975, 493: 2.2667, 494: 2.3366, 495: 2.3859, 496: 0.6615, 518: 0.4138, 519: 1.1717, 520: 1.6607, 521: 2.2957, 522: 2.3206, 523: 1.9782, 524: 0.021, 544: 0.3593, 545: 1.3416, 546: 2.0545, 547: 2.2783, 548: 2.2875, 549: 2.2774, 550: 2.2933, 551: 1.7754, 570: 0.22, 571: 1.0324, 572: 1.9874, 573: 2.2669, 574: 2.2696, 575: 2.2748, 576: 2.2744, 577: 1.8188, 578: 0.7322, 596: 0.2227, 597: 0.6063, 598: 1.9165, 599: 2.2699, 600: 2.2776, 601: 2.2925, 602: 2.2877, 603: 1.7844, 604: 0.7323, 605: 0.0186, 622: 0.2773, 623: 2.0469, 624: 2.2357, 625: 2.3634, 626: 2.2686, 627: 2.2418, 628: 2.2499, 629: 1.739, 630: 0.7129, 631: 0.0809, 648: 3.1738, 649: 5.777, 650: 4.8899, 651: 3.9084, 652: 3.0801, 653: 2.6436, 654: 2.4196, 655: 2.2354, 656: 1.2031, 657: 0.0998, 676: 14.4017, 677: 15.0629, 678: 9.2458, 679: 6.182, 680: 3.8245, 681: 1.9369, 682: 1.6289, 683: 0.1813}))"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  5.0|(784,[152,153,154...|\n|  0.0|(784,[127,128,129...|\n|  4.0|(784,[160,161,162...|\n|  1.0|(784,[158,159,160...|\n|  9.0|(784,[208,209,210...|\n+-----+--------------------+\nonly showing top 5 rows\n\nOut[30]: Row(label=5.0, features=SparseVector(784, {152: 0.0314, 153: 0.1746, 154: 0.168, 155: 0.1659, 156: 1.1678, 157: 1.2939, 158: 1.7689, 159: 0.2904, 160: 2.1633, 161: 4.121, 162: 5.1998, 163: 3.6403, 176: 0.4516, 177: 0.4471, 178: 1.0173, 179: 1.5176, 180: 1.5781, 181: 2.2789, 182: 2.2555, 183: 2.2522, 184: 2.2523, 185: 2.2559, 186: 2.0479, 187: 1.658, 188: 2.7184, 189: 3.0987, 190: 3.152, 191: 1.3923, 203: 0.7658, 204: 3.0105, 205: 2.742, 206: 2.4864, 207: 2.3542, 208: 2.301, 209: 2.2915, 210: 2.291, 211: 2.2974, 212: 2.2953, 213: 2.2679, 214: 0.838, 215: 0.7548, 216: 0.8114, 217: 0.6372, 218: 0.5509, 231: 0.2477, 232: 2.4867, 233: 2.5283, 234: 2.3593, 235: 2.2913, 236: 2.277, 237: 2.2717, 238: 1.7808, 239: 1.6426, 240: 2.2299, 241: 2.1708, 260: 0.8545, 261: 1.4945, 262: 0.9728, 263: 2.2701, 264: 2.2724, 265: 1.8618, 266: 0.1009, 268: 0.3933, 269: 1.3931, 289: 0.1317, 290: 0.0091, 291: 1.3902, 292: 2.3431, 293: 0.8648, 319: 1.2773, 320: 2.4313, 321: 1.8977, 322: 0.0195, 347: 0.1017, 348: 1.8272, 349: 2.4551, 350: 0.6428, 376: 0.3291, 377: 2.2168, 378: 1.9769, 379: 1.4336, 380: 0.9823, 381: 0.0089, 405: 0.7261, 406: 2.1103, 407: 2.31, 408: 2.3033, 409: 1.0589, 410: 0.2251, 434: 0.3996, 435: 1.7013, 436: 2.272, 437: 2.2466, 438: 1.3656, 439: 0.2592, 463: 0.1438, 464: 0.8293, 465: 2.2655, 466: 2.3315, 467: 1.7975, 493: 2.2667, 494: 2.3366, 495: 2.3859, 496: 0.6615, 518: 0.4138, 519: 1.1717, 520: 1.6607, 521: 2.2957, 522: 2.3206, 523: 1.9782, 524: 0.021, 544: 0.3593, 545: 1.3416, 546: 2.0545, 547: 2.2783, 548: 2.2875, 549: 2.2774, 550: 2.2933, 551: 1.7754, 570: 0.22, 571: 1.0324, 572: 1.9874, 573: 2.2669, 574: 2.2696, 575: 2.2748, 576: 2.2744, 577: 1.8188, 578: 0.7322, 596: 0.2227, 597: 0.6063, 598: 1.9165, 599: 2.2699, 600: 2.2776, 601: 2.2925, 602: 2.2877, 603: 1.7844, 604: 0.7323, 605: 0.0186, 622: 0.2773, 623: 2.0469, 624: 2.2357, 625: 2.3634, 626: 2.2686, 627: 2.2418, 628: 2.2499, 629: 1.739, 630: 0.7129, 631: 0.0809, 648: 3.1738, 649: 5.777, 650: 4.8899, 651: 3.9084, 652: 3.0801, 653: 2.6436, 654: 2.4196, 655: 2.2354, 656: 1.2031, 657: 0.0998, 676: 14.4017, 677: 15.0629, 678: 9.2458, 679: 6.182, 680: 3.8245, 681: 1.9369, 682: 1.6289, 683: 0.1813}))\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"32e6cc02-573d-4a1c-8415-f72f7a2e479d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### **1.e) Preparing the test DF**\nNow, let's load and preprocess the test data.\n\n**Exercise**: load the test data file (\"mnist.t\") and apply the normalization that you have already learned with the training data (i.e., the test data have to be normalized with the standard deviation of the training data). \n\nAs result, you have to provide a new DF, called \"testDF\", with the columns: \"label\" (where you have to store the test data labels) and \"features\" (where the normalized test data features have to be stored)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d0447e62-ae66-4a7e-8cb1-ce9056ba43f8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Load test data\ntestfileName = \"/FileStore/tables/mnist.t\"\ndataTestDF = spark.read.format(\"libsvm\").option(\"numFeatures\", \"784\").load(testfileName)\n# Normalize the test data\nscaledDataTest = scalerModel.transform(dataTestDF) # We use the pre-trained scaler. It is state-of-art behaviour to use scaler trained on training data on test data \n# Create the test DF\ntestDF = scaledDataTest.select(\"label\", scaledDataTest[\"normFeatures\"].alias(\"features\"))\n\n# Examine the resulting DF\ntestDF.show(5)\ntestDF.first()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8adcbbca-7299-410c-8acb-9dc0e1753ecb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  7.0|(784,[202,203,204...|\n|  2.0|(784,[94,95,96,97...|\n|  1.0|(784,[128,129,130...|\n|  0.0|(784,[124,125,126...|\n|  4.0|(784,[150,151,159...|\n+-----+--------------------+\nonly showing top 5 rows\n\nOut[16]: Row(label=7.0, features=SparseVector(784, {202: 1.7427, 203: 2.8914, 204: 2.0112, 205: 1.6365, 206: 0.5897, 207: 0.335, 230: 3.9602, 231: 3.4952, 232: 2.8841, 233: 2.5383, 234: 2.3686, 235: 2.1827, 236: 1.782, 237: 1.7779, 238: 1.7808, 239: 1.787, 240: 1.7876, 241: 1.7835, 242: 1.7776, 243: 1.7967, 244: 1.6253, 245: 0.5613, 258: 1.1105, 259: 1.4607, 260: 0.769, 261: 1.0921, 262: 1.482, 263: 2.0368, 264: 2.2814, 265: 2.0434, 266: 2.3308, 267: 2.3357, 268: 2.3232, 269: 2.2616, 270: 2.0605, 271: 2.3095, 272: 2.4288, 273: 1.5077, 291: 0.1535, 292: 0.6113, 293: 0.1345, 294: 0.6507, 295: 0.6369, 296: 0.6238, 297: 0.5376, 298: 0.1901, 299: 2.1627, 300: 2.4793, 301: 1.1789, 326: 0.7517, 327: 2.3442, 328: 2.111, 329: 0.2115, 353: 0.198, 354: 2.0945, 355: 2.397, 356: 0.8737, 381: 1.1503, 382: 2.277, 383: 2.2733, 384: 0.4736, 408: 0.5371, 409: 2.2157, 410: 2.2868, 411: 0.5946, 436: 1.1944, 437: 2.2555, 438: 1.7024, 439: 0.048, 463: 0.0809, 464: 1.828, 465: 2.2296, 466: 0.5345, 491: 1.1273, 492: 2.287, 493: 1.6568, 518: 0.6746, 519: 2.2622, 520: 2.1779, 521: 0.5172, 545: 0.1722, 546: 1.9827, 547: 2.2873, 548: 1.5009, 572: 0.027, 573: 1.8189, 574: 2.2785, 575: 1.9691, 576: 0.3146, 600: 0.3421, 601: 2.3015, 602: 2.2967, 603: 0.6939, 627: 0.2747, 628: 1.992, 629: 2.2651, 630: 1.0248, 631: 0.009, 655: 1.2185, 656: 2.2977, 657: 2.3047, 658: 0.482, 682: 0.7527, 683: 2.7424, 684: 2.7881, 685: 2.8049, 686: 0.6033, 710: 2.3262, 711: 4.4795, 712: 4.3152, 713: 3.7599, 714: 0.7319, 738: 3.9295, 739: 7.4372, 740: 5.8657, 741: 0.5192}))","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  7.0|(784,[202,203,204...|\n|  2.0|(784,[94,95,96,97...|\n|  1.0|(784,[128,129,130...|\n|  0.0|(784,[124,125,126...|\n|  4.0|(784,[150,151,159...|\n+-----+--------------------+\nonly showing top 5 rows\n\nOut[16]: Row(label=7.0, features=SparseVector(784, {202: 1.7427, 203: 2.8914, 204: 2.0112, 205: 1.6365, 206: 0.5897, 207: 0.335, 230: 3.9602, 231: 3.4952, 232: 2.8841, 233: 2.5383, 234: 2.3686, 235: 2.1827, 236: 1.782, 237: 1.7779, 238: 1.7808, 239: 1.787, 240: 1.7876, 241: 1.7835, 242: 1.7776, 243: 1.7967, 244: 1.6253, 245: 0.5613, 258: 1.1105, 259: 1.4607, 260: 0.769, 261: 1.0921, 262: 1.482, 263: 2.0368, 264: 2.2814, 265: 2.0434, 266: 2.3308, 267: 2.3357, 268: 2.3232, 269: 2.2616, 270: 2.0605, 271: 2.3095, 272: 2.4288, 273: 1.5077, 291: 0.1535, 292: 0.6113, 293: 0.1345, 294: 0.6507, 295: 0.6369, 296: 0.6238, 297: 0.5376, 298: 0.1901, 299: 2.1627, 300: 2.4793, 301: 1.1789, 326: 0.7517, 327: 2.3442, 328: 2.111, 329: 0.2115, 353: 0.198, 354: 2.0945, 355: 2.397, 356: 0.8737, 381: 1.1503, 382: 2.277, 383: 2.2733, 384: 0.4736, 408: 0.5371, 409: 2.2157, 410: 2.2868, 411: 0.5946, 436: 1.1944, 437: 2.2555, 438: 1.7024, 439: 0.048, 463: 0.0809, 464: 1.828, 465: 2.2296, 466: 0.5345, 491: 1.1273, 492: 2.287, 493: 1.6568, 518: 0.6746, 519: 2.2622, 520: 2.1779, 521: 0.5172, 545: 0.1722, 546: 1.9827, 547: 2.2873, 548: 1.5009, 572: 0.027, 573: 1.8189, 574: 2.2785, 575: 1.9691, 576: 0.3146, 600: 0.3421, 601: 2.3015, 602: 2.2967, 603: 0.6939, 627: 0.2747, 628: 1.992, 629: 2.2651, 630: 1.0248, 631: 0.009, 655: 1.2185, 656: 2.2977, 657: 2.3047, 658: 0.482, 682: 0.7527, 683: 2.7424, 684: 2.7881, 685: 2.8049, 686: 0.6033, 710: 2.3262, 711: 4.4795, 712: 4.3152, 713: 3.7599, 714: 0.7319, 738: 3.9295, 739: 7.4372, 740: 5.8657, 741: 0.5192}))"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\ndataTestDF:pyspark.sql.dataframe.DataFrame = [label: double, features: udt]\nscaledDataTest:pyspark.sql.dataframe.DataFrame = [label: double, features: udt ... 1 more fields]\ntestDF:pyspark.sql.dataframe.DataFrame = [label: double, features: udt]\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  7.0|(784,[202,203,204...|\n|  2.0|(784,[94,95,96,97...|\n|  1.0|(784,[128,129,130...|\n|  0.0|(784,[124,125,126...|\n|  4.0|(784,[150,151,159...|\n+-----+--------------------+\nonly showing top 5 rows\n\nOut[31]: Row(label=7.0, features=SparseVector(784, {202: 1.7427, 203: 2.8914, 204: 2.0112, 205: 1.6365, 206: 0.5897, 207: 0.335, 230: 3.9602, 231: 3.4952, 232: 2.8841, 233: 2.5383, 234: 2.3686, 235: 2.1827, 236: 1.782, 237: 1.7779, 238: 1.7808, 239: 1.787, 240: 1.7876, 241: 1.7835, 242: 1.7776, 243: 1.7967, 244: 1.6253, 245: 0.5613, 258: 1.1105, 259: 1.4607, 260: 0.769, 261: 1.0921, 262: 1.482, 263: 2.0368, 264: 2.2814, 265: 2.0434, 266: 2.3308, 267: 2.3357, 268: 2.3232, 269: 2.2616, 270: 2.0605, 271: 2.3095, 272: 2.4288, 273: 1.5077, 291: 0.1535, 292: 0.6113, 293: 0.1345, 294: 0.6507, 295: 0.6369, 296: 0.6238, 297: 0.5376, 298: 0.1901, 299: 2.1627, 300: 2.4793, 301: 1.1789, 326: 0.7517, 327: 2.3442, 328: 2.111, 329: 0.2115, 353: 0.198, 354: 2.0945, 355: 2.397, 356: 0.8737, 381: 1.1503, 382: 2.277, 383: 2.2733, 384: 0.4736, 408: 0.5371, 409: 2.2157, 410: 2.2868, 411: 0.5946, 436: 1.1944, 437: 2.2555, 438: 1.7024, 439: 0.048, 463: 0.0809, 464: 1.828, 465: 2.2296, 466: 0.5345, 491: 1.1273, 492: 2.287, 493: 1.6568, 518: 0.6746, 519: 2.2622, 520: 2.1779, 521: 0.5172, 545: 0.1722, 546: 1.9827, 547: 2.2873, 548: 1.5009, 572: 0.027, 573: 1.8189, 574: 2.2785, 575: 1.9691, 576: 0.3146, 600: 0.3421, 601: 2.3015, 602: 2.2967, 603: 0.6939, 627: 0.2747, 628: 1.992, 629: 2.2651, 630: 1.0248, 631: 0.009, 655: 1.2185, 656: 2.2977, 657: 2.3047, 658: 0.482, 682: 0.7527, 683: 2.7424, 684: 2.7881, 685: 2.8049, 686: 0.6033, 710: 2.3262, 711: 4.4795, 712: 4.3152, 713: 3.7599, 714: 0.7319, 738: 3.9295, 739: 7.4372, 740: 5.8657, 741: 0.5192}))\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f07cc50b-d291-4cb3-9ed9-4b0d8ba0d770","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## **2. Solving classification problems**\n\nMLLIB includes distributed implementations of the most common classifiers, such as, logistic regression, decission trees, random forest or linear SVMs. In this notebook, we are going to use the linear SVM as classifier. But the procedure to train, predict and evaluate this classifier would be similar to any of the other classifiers, so you can easily extend the content of this notebook to other classifiers."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6af7e148-df03-4452-a49c-04c718d4484e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**2.a) Binary classification with SVMs**\n\nAs you know, standard SVM is a binary classifier. So, to start to work with this classifier, let's convert the multiclass original problem to a binary one by solving the problem of differentiating the digits \"3\" from the digits \"5\"."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7b2911a4-2b8e-40d9-bdfd-f87a2afd23bd","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**Exercise**: Built the binary DFs for training and testing by following these steps:\n1. Select form the \"trainDF\" and \"testDF\" the rows with label \"3\" or \"5\" (use filter()). \n2. Convert the label values of the resulting DF to the binary values \"0\" and \"1\". For this purpose, you can use the \"changeLabels\" UDF defined in the next cell."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b0e494d-497e-4976-8e81-41bf218a0748","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.types import *\n# User defined function to convert labels \"3\" and \"5\" to binary values \"1\" and \"0\" \nchangeLabels = udf(lambda label: 1 if (label==3) else 0, IntegerType())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"980fec60-96ff-460a-9987-8c3039a2fc50","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create the training DF for the binary problem 3 vs 5\n\n##¬†Select digits 3 and 5\ntrainDFBinaryAux= trainDF.filter((trainDF.label == 3) | (trainDF.label == 5))\n## Convert labels to 0 and 1\ntrainDFBinary = trainDFBinaryAux.select(changeLabels(\"label\").alias(\"label\"), \"features\")\n\ntrainDFBinary.show(5)\nprint ( 'Number of traning samples ' + str(trainDFBinary.count()) )\n\n# Create the test DF for the binary problem 3 vs 5\n\n##¬†Select digits 3 and 5\ntestDFBinaryAux = testDF.filter((testDF.label == 3) | (testDF.label == 5))\n## Convert labels to 0 and 1\ntestDFBinary = testDFBinaryAux.select(changeLabels(\"label\").alias(\"label\"), \"features\")\ntestDFBinary.show(5)\nprint ( 'Number of test samples ' + str(testDFBinary.count()) )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"60cc5e8d-e47f-4e7b-a648-a8384c2c6c64","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|(784,[152,153,154...|\n|    1|(784,[151,152,153...|\n|    1|(784,[123,124,125...|\n|    0|(784,[216,217,218...|\n|    1|(784,[143,144,145...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of traning samples 11552\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|(784,[129,130,131...|\n|    0|(784,[124,125,126...|\n|    1|(784,[118,119,120...|\n|    0|(784,[156,157,158...|\n|    1|(784,[175,176,177...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of test samples 1902\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|(784,[152,153,154...|\n|    1|(784,[151,152,153...|\n|    1|(784,[123,124,125...|\n|    0|(784,[216,217,218...|\n|    1|(784,[143,144,145...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of traning samples 11552\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|(784,[129,130,131...|\n|    0|(784,[124,125,126...|\n|    1|(784,[118,119,120...|\n|    0|(784,[156,157,158...|\n|    1|(784,[175,176,177...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of test samples 1902\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|(784,[152,153,154...|\n|    1|(784,[151,152,153...|\n|    1|(784,[123,124,125...|\n|    0|(784,[216,217,218...|\n|    1|(784,[143,144,145...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of traning samples 11552\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|    0|(784,[129,130,131...|\n|    0|(784,[124,125,126...|\n|    1|(784,[118,119,120...|\n|    0|(784,[156,157,158...|\n|    1|(784,[175,176,177...|\n+-----+--------------------+\nonly showing top 5 rows\n\nNumber of test samples 1902\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"031d7156-df57-4f5c-b4bc-911122737351","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**Exercise**: Train a binary [linear SVM classifier](https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine) able to differenciate digits 3 from digits 5. Show the coefficients and bias (or intercept) of the resulting classifier.\n\n*Note:* After training the lsvc object, you will obtain a new object (lsvcModel) with the trained SVM. Remember that you can check their parameters and methods typing help(lsvcModel)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d30a3cec-1700-4377-803c-97e3b3eb2a3c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC\n\n# Define your classifier\nlsvc = LinearSVC(maxIter=10, regParam=0.1)\n\n# Fit the model\nlsvcModel = lsvc.fit(trainDFBinary)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f825379-e968-47d9-a821-c39d621a3e5d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Print the coefficients and intercept for linearsSVC\ncoefficients = lsvcModel.coefficients\nintercept = lsvcModel.intercept\nprint(\"Some coefficients: \" + str(coefficients[250:300]))\nprint(\"Intercept: \" + str(intercept))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"955b4ec8-f273-4811-8c08-6e2a1c98592f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Some coefficients: [-0.00503628 -0.00132885  0.          0.00126173  0.00227966  0.02608547\n  0.05871618  0.03443694  0.02193514  0.00136647 -0.02733835 -0.04217431\n -0.06044608 -0.08564233 -0.06133984 -0.00355557  0.05431954  0.09815572\n  0.08667559  0.06678955  0.05470663  0.03951634  0.02318501 -0.0065486\n -0.04603254 -0.08474889 -0.06036465 -0.02330273 -0.00422041 -0.00138298\n  0.          0.0029333   0.00626491  0.03212335  0.03057417  0.0191151\n -0.00570462 -0.03476342 -0.06753077 -0.08810949 -0.09415329 -0.11641097\n -0.08013833 -0.00184359  0.05084453  0.0723497   0.07656243  0.08159644\n  0.08968747  0.07798104]\nIntercept: -1.0881673468738582\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Some coefficients: [-0.00503628 -0.00132885  0.          0.00126173  0.00227966  0.02608547\n  0.05871618  0.03443694  0.02193514  0.00136647 -0.02733835 -0.04217431\n -0.06044608 -0.08564233 -0.06133984 -0.00355557  0.05431954  0.09815572\n  0.08667559  0.06678955  0.05470663  0.03951634  0.02318501 -0.0065486\n -0.04603254 -0.08474889 -0.06036465 -0.02330273 -0.00422041 -0.00138298\n  0.          0.0029333   0.00626491  0.03212335  0.03057417  0.0191151\n -0.00570462 -0.03476342 -0.06753077 -0.08810949 -0.09415329 -0.11641097\n -0.08013833 -0.00184359  0.05084453  0.0723497   0.07656243  0.08159644\n  0.08968747  0.07798104]\nIntercept: -1.0881673468738582\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\nSome coefficients: [-0.00811581 -0.00155393  0.          0.00075426  0.00546287  0.01589203\n  0.02332875  0.02345315  0.01133168  0.00204586 -0.01587148 -0.03831883\n -0.05673717 -0.06903806 -0.04944357 -0.0330097  -0.00822104  0.02422009\n  0.0333946   0.03522194  0.03150301  0.02456392  0.01293632 -0.0133156\n -0.02713423 -0.0401274  -0.03177593 -0.01787716 -0.00728533 -0.00161424\n  0.          0.00175353  0.00669578  0.01628817  0.01763349  0.00970026\n -0.00178221 -0.02566225 -0.05377013 -0.07652784 -0.08909582 -0.08746426\n -0.05756012 -0.01961768  0.01662599  0.03718076  0.04844331  0.05106937\n  0.04733887  0.03992283]\nIntercept: -0.00149776081873\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1901dbee-8eb6-4071-abce-d9b1d4c31bf1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["help(lsvcModel)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e9d9fcb-8e60-4373-8cf4-d1bfef0835d0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Help on LinearSVCModel in module pyspark.ml.classification object:\n\nclass LinearSVCModel(_JavaClassificationModel, _LinearSVCParams, pyspark.ml.util.JavaMLWritable, pyspark.ml.util.JavaMLReadable, pyspark.ml.util.HasTrainingSummary)\n |  LinearSVCModel(java_model=None)\n |  \n |  Model fitted by LinearSVC.\n |  \n |  .. versionadded:: 2.2.0\n |  \n |  Method resolution order:\n |      LinearSVCModel\n |      _JavaClassificationModel\n |      ClassificationModel\n |      pyspark.ml.wrapper.JavaPredictionModel\n |      pyspark.ml.base.PredictionModel\n |      pyspark.ml.wrapper.JavaModel\n |      pyspark.ml.wrapper.JavaTransformer\n |      pyspark.ml.wrapper.JavaParams\n |      pyspark.ml.wrapper.JavaWrapper\n |      pyspark.ml.base.Model\n |      pyspark.ml.base.Transformer\n |      _LinearSVCParams\n |      _ClassifierParams\n |      pyspark.ml.param.shared.HasRawPredictionCol\n |      pyspark.ml.base._PredictorParams\n |      pyspark.ml.param.shared.HasLabelCol\n |      pyspark.ml.param.shared.HasFeaturesCol\n |      pyspark.ml.param.shared.HasPredictionCol\n |      pyspark.ml.param.shared.HasRegParam\n |      pyspark.ml.param.shared.HasMaxIter\n |      pyspark.ml.param.shared.HasFitIntercept\n |      pyspark.ml.param.shared.HasTol\n |      pyspark.ml.param.shared.HasStandardization\n |      pyspark.ml.param.shared.HasWeightCol\n |      pyspark.ml.param.shared.HasAggregationDepth\n |      pyspark.ml.param.shared.HasThreshold\n |      pyspark.ml.param.shared.HasMaxBlockSizeInMB\n |      pyspark.ml.param.Params\n |      pyspark.ml.util.Identifiable\n |      pyspark.ml.util.JavaMLWritable\n |      pyspark.ml.util.MLWritable\n |      pyspark.ml.util.JavaMLReadable\n |      pyspark.ml.util.MLReadable\n |      pyspark.ml.util.HasTrainingSummary\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  evaluate(self, dataset)\n |      Evaluates the model on a test dataset.\n |      \n |      .. versionadded:: 3.1.0\n |      \n |      Parameters\n |      ----------\n |      dataset : :py:class:`pyspark.sql.DataFrame`\n |          Test dataset to evaluate model on.\n |  \n |  setThreshold(self, value)\n |      Sets the value of :py:attr:`threshold`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  summary(self)\n |      Gets summary (accuracy/precision/recall, objective history, total iterations) of model\n |      trained on the training set. An exception is thrown if `trainingSummary is None`.\n |      \n |      .. versionadded:: 3.1.0\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  coefficients\n |      Model coefficients of Linear SVM Classifier.\n |      \n |      .. versionadded:: 2.2.0\n |  \n |  intercept\n |      Model intercept of Linear SVM Classifier.\n |      \n |      .. versionadded:: 2.2.0\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _JavaClassificationModel:\n |  \n |  predictRaw(self, value)\n |      Raw prediction for each possible label.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from _JavaClassificationModel:\n |  \n |  numClasses\n |      Number of classes (values which the label can take).\n |      \n |      .. versionadded:: 2.1.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from ClassificationModel:\n |  \n |  setRawPredictionCol(self, value)\n |      Sets the value of :py:attr:`rawPredictionCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaPredictionModel:\n |  \n |  predict(self, value)\n |      Predict label for the given features.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.wrapper.JavaPredictionModel:\n |  \n |  numFeatures\n |      Returns the number of features the model was trained on. If unknown, returns -1\n |      \n |      .. versionadded:: 2.1.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.PredictionModel:\n |  \n |  setFeaturesCol(self, value)\n |      Sets the value of :py:attr:`featuresCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  setPredictionCol(self, value)\n |      Sets the value of :py:attr:`predictionCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaModel:\n |  \n |  __init__(self, java_model=None)\n |      Initialize this instance with a Java model object.\n |      Subclasses should call this constructor, initialize params,\n |      and then call _transfer_params_from_java.\n |      \n |      This instance can be instantiated without specifying java_model,\n |      it will be assigned after that, but this scenario only used by\n |      :py:class:`JavaMLReader` to load models.  This is a bit of a\n |      hack, but it is easiest since a proper fix would require\n |      MLReader (in pyspark.ml.util) to depend on these wrappers, but\n |      these wrappers depend on pyspark.ml.util (both directly and via\n |      other ML classes).\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaParams:\n |  \n |  clear(self, param)\n |      Clears a param from the param map if it has been explicitly set.\n |  \n |  copy(self, extra=None)\n |      Creates a copy of this instance with the same uid and some\n |      extra params. This implementation first calls Params.copy and\n |      then make a copy of the companion Java pipeline component with\n |      extra params. So both the Python wrapper and the Java pipeline\n |      component get copied.\n |      \n |      Parameters\n |      ----------\n |      extra : dict, optional\n |          Extra parameters to copy to the new instance\n |      \n |      Returns\n |      -------\n |      :py:class:`JavaParams`\n |          Copy of this instance\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __del__(self)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.Model:\n |  \n |  transform(self, dataset, params=None)\n |      Transforms the input dataset with optional parameters.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      dataset : :py:class:`pyspark.sql.DataFrame`\n |          input dataset\n |      params : dict, optional\n |          an optional param map that overrides embedded params.\n |      \n |      Returns\n |      -------\n |      :py:class:`pyspark.sql.DataFrame`\n |          transformed dataset\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from _LinearSVCParams:\n |  \n |  threshold = Param(parent='undefined', name='threshold', doc=...ons 0.0...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasRawPredictionCol:\n |  \n |  getRawPredictionCol(self)\n |      Gets the value of rawPredictionCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasRawPredictionCol:\n |  \n |  rawPredictionCol = Param(parent='undefined', name='rawPredictionCol......\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  getLabelCol(self)\n |      Gets the value of labelCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  labelCol = Param(parent='undefined', name='labelCol', doc='label colum...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  getFeaturesCol(self)\n |      Gets the value of featuresCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  featuresCol = Param(parent='undefined', name='featuresCol', doc='featu...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  getPredictionCol(self)\n |      Gets the value of predictionCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  predictionCol = Param(parent='undefined', name='predictionCol', doc='p...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasRegParam:\n |  \n |  getRegParam(self)\n |      Gets the value of regParam or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasRegParam:\n |  \n |  regParam = Param(parent='undefined', name='regParam', doc='regularizat...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasMaxIter:\n |  \n |  getMaxIter(self)\n |      Gets the value of maxIter or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxIter:\n |  \n |  maxIter = Param(parent='undefined', name='maxIter', doc='max number of...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFitIntercept:\n |  \n |  getFitIntercept(self)\n |      Gets the value of fitIntercept or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFitIntercept:\n |  \n |  fitIntercept = Param(parent='undefined', name='fitIntercept', doc='whe...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasTol:\n |  \n |  getTol(self)\n |      Gets the value of tol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasTol:\n |  \n |  tol = Param(parent='undefined', name='tol', doc='the c...ence toleranc...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasStandardization:\n |  \n |  getStandardization(self)\n |      Gets the value of standardization or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasStandardization:\n |  \n |  standardization = Param(parent='undefined', name='standardization'...t...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasWeightCol:\n |  \n |  getWeightCol(self)\n |      Gets the value of weightCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasWeightCol:\n |  \n |  weightCol = Param(parent='undefined', name='weightCol', doc=...or empt...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasAggregationDepth:\n |  \n |  getAggregationDepth(self)\n |      Gets the value of aggregationDepth or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasAggregationDepth:\n |  \n |  aggregationDepth = Param(parent='undefined', name='aggregationDepth', ...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasThreshold:\n |  \n |  getThreshold(self)\n |      Gets the value of threshold or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasMaxBlockSizeInMB:\n |  \n |  getMaxBlockSizeInMB(self)\n |      Gets the value of maxBlockSizeInMB or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxBlockSizeInMB:\n |  \n |  maxBlockSizeInMB = Param(parent='undefined', name='maxBlockSizeInMB......\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.Params:\n |  \n |  explainParam(self, param)\n |      Explains a single param and returns its name, doc, and optional\n |      default value and user-supplied value in a string.\n |  \n |  explainParams(self)\n |      Returns the documentation of all params with their optionally\n |      default values and user-supplied values.\n |  \n |  extractParamMap(self, extra=None)\n |      Extracts the embedded default param values and user-supplied\n |      values, and then merges them with extra values from input into\n |      a flat param map, where the latter value is used if there exist\n |      conflicts, i.e., with ordering: default param values <\n |      user-supplied values < extra.\n |      \n |      Parameters\n |      ----------\n |      extra : dict, optional\n |          extra param values\n |      \n |      Returns\n |      -------\n |      dict\n |          merged param map\n |  \n |  getOrDefault(self, param)\n |      Gets the value of a param in the user-supplied param map or its\n |      default value. Raises an error if neither is set.\n |  \n |  getParam(self, paramName)\n |      Gets a param by its name.\n |  \n |  hasDefault(self, param)\n |      Checks whether a param has a default value.\n |  \n |  hasParam(self, paramName)\n |      Tests whether this instance contains a param with a given\n |      (string) name.\n |  \n |  isDefined(self, param)\n |      Checks whether a param is explicitly set by user or has\n |      a default value.\n |  \n |  isSet(self, param)\n |      Checks whether a param is explicitly set by user.\n |  \n |  set(self, param, value)\n |      Sets a parameter in the embedded param map.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.param.Params:\n |  \n |  params\n |      Returns all params ordered by name. The default implementation\n |      uses :py:func:`dir` to get all attributes of type\n |      :py:class:`Param`.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.JavaMLWritable:\n |  \n |  write(self)\n |      Returns an MLWriter instance for this ML instance.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.MLWritable:\n |  \n |  save(self, path)\n |      Save this ML instance to the given path, a shortcut of 'write().save(path)'.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.JavaMLReadable:\n |  \n |  read() from abc.ABCMeta\n |      Returns an MLReader instance for this class.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.MLReadable:\n |  \n |  load(path) from abc.ABCMeta\n |      Reads an ML instance from the input path, a shortcut of `read().load(path)`.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.util.HasTrainingSummary:\n |  \n |  hasSummary\n |      Indicates whether a training summary exists for this model\n |      instance.\n |      \n |      .. versionadded:: 2.1.0\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on LinearSVCModel in module pyspark.ml.classification object:\n\nclass LinearSVCModel(_JavaClassificationModel, _LinearSVCParams, pyspark.ml.util.JavaMLWritable, pyspark.ml.util.JavaMLReadable, pyspark.ml.util.HasTrainingSummary)\n |  LinearSVCModel(java_model=None)\n |  \n |  Model fitted by LinearSVC.\n |  \n |  .. versionadded:: 2.2.0\n |  \n |  Method resolution order:\n |      LinearSVCModel\n |      _JavaClassificationModel\n |      ClassificationModel\n |      pyspark.ml.wrapper.JavaPredictionModel\n |      pyspark.ml.base.PredictionModel\n |      pyspark.ml.wrapper.JavaModel\n |      pyspark.ml.wrapper.JavaTransformer\n |      pyspark.ml.wrapper.JavaParams\n |      pyspark.ml.wrapper.JavaWrapper\n |      pyspark.ml.base.Model\n |      pyspark.ml.base.Transformer\n |      _LinearSVCParams\n |      _ClassifierParams\n |      pyspark.ml.param.shared.HasRawPredictionCol\n |      pyspark.ml.base._PredictorParams\n |      pyspark.ml.param.shared.HasLabelCol\n |      pyspark.ml.param.shared.HasFeaturesCol\n |      pyspark.ml.param.shared.HasPredictionCol\n |      pyspark.ml.param.shared.HasRegParam\n |      pyspark.ml.param.shared.HasMaxIter\n |      pyspark.ml.param.shared.HasFitIntercept\n |      pyspark.ml.param.shared.HasTol\n |      pyspark.ml.param.shared.HasStandardization\n |      pyspark.ml.param.shared.HasWeightCol\n |      pyspark.ml.param.shared.HasAggregationDepth\n |      pyspark.ml.param.shared.HasThreshold\n |      pyspark.ml.param.shared.HasMaxBlockSizeInMB\n |      pyspark.ml.param.Params\n |      pyspark.ml.util.Identifiable\n |      pyspark.ml.util.JavaMLWritable\n |      pyspark.ml.util.MLWritable\n |      pyspark.ml.util.JavaMLReadable\n |      pyspark.ml.util.MLReadable\n |      pyspark.ml.util.HasTrainingSummary\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  evaluate(self, dataset)\n |      Evaluates the model on a test dataset.\n |      \n |      .. versionadded:: 3.1.0\n |      \n |      Parameters\n |      ----------\n |      dataset : :py:class:`pyspark.sql.DataFrame`\n |          Test dataset to evaluate model on.\n |  \n |  setThreshold(self, value)\n |      Sets the value of :py:attr:`threshold`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  summary(self)\n |      Gets summary (accuracy/precision/recall, objective history, total iterations) of model\n |      trained on the training set. An exception is thrown if `trainingSummary is None`.\n |      \n |      .. versionadded:: 3.1.0\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  coefficients\n |      Model coefficients of Linear SVM Classifier.\n |      \n |      .. versionadded:: 2.2.0\n |  \n |  intercept\n |      Model intercept of Linear SVM Classifier.\n |      \n |      .. versionadded:: 2.2.0\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __abstractmethods__ = frozenset()\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from _JavaClassificationModel:\n |  \n |  predictRaw(self, value)\n |      Raw prediction for each possible label.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from _JavaClassificationModel:\n |  \n |  numClasses\n |      Number of classes (values which the label can take).\n |      \n |      .. versionadded:: 2.1.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from ClassificationModel:\n |  \n |  setRawPredictionCol(self, value)\n |      Sets the value of :py:attr:`rawPredictionCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaPredictionModel:\n |  \n |  predict(self, value)\n |      Predict label for the given features.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.wrapper.JavaPredictionModel:\n |  \n |  numFeatures\n |      Returns the number of features the model was trained on. If unknown, returns -1\n |      \n |      .. versionadded:: 2.1.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.PredictionModel:\n |  \n |  setFeaturesCol(self, value)\n |      Sets the value of :py:attr:`featuresCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  setPredictionCol(self, value)\n |      Sets the value of :py:attr:`predictionCol`.\n |      \n |      .. versionadded:: 3.0.0\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaModel:\n |  \n |  __init__(self, java_model=None)\n |      Initialize this instance with a Java model object.\n |      Subclasses should call this constructor, initialize params,\n |      and then call _transfer_params_from_java.\n |      \n |      This instance can be instantiated without specifying java_model,\n |      it will be assigned after that, but this scenario only used by\n |      :py:class:`JavaMLReader` to load models.  This is a bit of a\n |      hack, but it is easiest since a proper fix would require\n |      MLReader (in pyspark.ml.util) to depend on these wrappers, but\n |      these wrappers depend on pyspark.ml.util (both directly and via\n |      other ML classes).\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaParams:\n |  \n |  clear(self, param)\n |      Clears a param from the param map if it has been explicitly set.\n |  \n |  copy(self, extra=None)\n |      Creates a copy of this instance with the same uid and some\n |      extra params. This implementation first calls Params.copy and\n |      then make a copy of the companion Java pipeline component with\n |      extra params. So both the Python wrapper and the Java pipeline\n |      component get copied.\n |      \n |      Parameters\n |      ----------\n |      extra : dict, optional\n |          Extra parameters to copy to the new instance\n |      \n |      Returns\n |      -------\n |      :py:class:`JavaParams`\n |          Copy of this instance\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __del__(self)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from pyspark.ml.wrapper.JavaWrapper:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.base.Model:\n |  \n |  transform(self, dataset, params=None)\n |      Transforms the input dataset with optional parameters.\n |      \n |      .. versionadded:: 1.3.0\n |      \n |      Parameters\n |      ----------\n |      dataset : :py:class:`pyspark.sql.DataFrame`\n |          input dataset\n |      params : dict, optional\n |          an optional param map that overrides embedded params.\n |      \n |      Returns\n |      -------\n |      :py:class:`pyspark.sql.DataFrame`\n |          transformed dataset\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from _LinearSVCParams:\n |  \n |  threshold = Param(parent='undefined', name='threshold', doc=...ons 0.0...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasRawPredictionCol:\n |  \n |  getRawPredictionCol(self)\n |      Gets the value of rawPredictionCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasRawPredictionCol:\n |  \n |  rawPredictionCol = Param(parent='undefined', name='rawPredictionCol......\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  getLabelCol(self)\n |      Gets the value of labelCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasLabelCol:\n |  \n |  labelCol = Param(parent='undefined', name='labelCol', doc='label colum...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  getFeaturesCol(self)\n |      Gets the value of featuresCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFeaturesCol:\n |  \n |  featuresCol = Param(parent='undefined', name='featuresCol', doc='featu...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  getPredictionCol(self)\n |      Gets the value of predictionCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasPredictionCol:\n |  \n |  predictionCol = Param(parent='undefined', name='predictionCol', doc='p...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasRegParam:\n |  \n |  getRegParam(self)\n |      Gets the value of regParam or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasRegParam:\n |  \n |  regParam = Param(parent='undefined', name='regParam', doc='regularizat...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasMaxIter:\n |  \n |  getMaxIter(self)\n |      Gets the value of maxIter or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxIter:\n |  \n |  maxIter = Param(parent='undefined', name='maxIter', doc='max number of...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasFitIntercept:\n |  \n |  getFitIntercept(self)\n |      Gets the value of fitIntercept or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasFitIntercept:\n |  \n |  fitIntercept = Param(parent='undefined', name='fitIntercept', doc='whe...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasTol:\n |  \n |  getTol(self)\n |      Gets the value of tol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasTol:\n |  \n |  tol = Param(parent='undefined', name='tol', doc='the c...ence toleranc...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasStandardization:\n |  \n |  getStandardization(self)\n |      Gets the value of standardization or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasStandardization:\n |  \n |  standardization = Param(parent='undefined', name='standardization'...t...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasWeightCol:\n |  \n |  getWeightCol(self)\n |      Gets the value of weightCol or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasWeightCol:\n |  \n |  weightCol = Param(parent='undefined', name='weightCol', doc=...or empt...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasAggregationDepth:\n |  \n |  getAggregationDepth(self)\n |      Gets the value of aggregationDepth or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasAggregationDepth:\n |  \n |  aggregationDepth = Param(parent='undefined', name='aggregationDepth', ...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasThreshold:\n |  \n |  getThreshold(self)\n |      Gets the value of threshold or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.shared.HasMaxBlockSizeInMB:\n |  \n |  getMaxBlockSizeInMB(self)\n |      Gets the value of maxBlockSizeInMB or its default value.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from pyspark.ml.param.shared.HasMaxBlockSizeInMB:\n |  \n |  maxBlockSizeInMB = Param(parent='undefined', name='maxBlockSizeInMB......\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.param.Params:\n |  \n |  explainParam(self, param)\n |      Explains a single param and returns its name, doc, and optional\n |      default value and user-supplied value in a string.\n |  \n |  explainParams(self)\n |      Returns the documentation of all params with their optionally\n |      default values and user-supplied values.\n |  \n |  extractParamMap(self, extra=None)\n |      Extracts the embedded default param values and user-supplied\n |      values, and then merges them with extra values from input into\n |      a flat param map, where the latter value is used if there exist\n |      conflicts, i.e., with ordering: default param values <\n |      user-supplied values < extra.\n |      \n |      Parameters\n |      ----------\n |      extra : dict, optional\n |          extra param values\n |      \n |      Returns\n |      -------\n |      dict\n |          merged param map\n |  \n |  getOrDefault(self, param)\n |      Gets the value of a param in the user-supplied param map or its\n |      default value. Raises an error if neither is set.\n |  \n |  getParam(self, paramName)\n |      Gets a param by its name.\n |  \n |  hasDefault(self, param)\n |      Checks whether a param has a default value.\n |  \n |  hasParam(self, paramName)\n |      Tests whether this instance contains a param with a given\n |      (string) name.\n |  \n |  isDefined(self, param)\n |      Checks whether a param is explicitly set by user or has\n |      a default value.\n |  \n |  isSet(self, param)\n |      Checks whether a param is explicitly set by user.\n |  \n |  set(self, param, value)\n |      Sets a parameter in the embedded param map.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.param.Params:\n |  \n |  params\n |      Returns all params ordered by name. The default implementation\n |      uses :py:func:`dir` to get all attributes of type\n |      :py:class:`Param`.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.JavaMLWritable:\n |  \n |  write(self)\n |      Returns an MLWriter instance for this ML instance.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from pyspark.ml.util.MLWritable:\n |  \n |  save(self, path)\n |      Save this ML instance to the given path, a shortcut of 'write().save(path)'.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.JavaMLReadable:\n |  \n |  read() from abc.ABCMeta\n |      Returns an MLReader instance for this class.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from pyspark.ml.util.MLReadable:\n |  \n |  load(path) from abc.ABCMeta\n |      Reads an ML instance from the input path, a shortcut of `read().load(path)`.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from pyspark.ml.util.HasTrainingSummary:\n |  \n |  hasSummary\n |      Indicates whether a training summary exists for this model\n |      instance.\n |      \n |      .. versionadded:: 2.1.0\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**2.b) SVM evaluation**\n\n**Exercise**: Compute the SVM output over the test data and compute the SVM accuracy (percentage of correctly classified data) over the test data.\n\n*Note 1:* To compute the predictions of a MLLIB classifier over a DF, you can use the method \"transform\" of the classifier model (lsvcModel).\n\n*Note 2:* MLLIB includes two objects two evaluate the performance of classification problems:\n* [BinaryClassificationEvaluator](https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html#binary-classification) which only includes specific measurements for binary problems, such as, the AUC (\"areaUnderROC\") and area under the Precision-Recall curve (\"areaUnderPR\").\n* [MulticlassClassificationEvaluator](https://spark.apache.org/docs/2.2.0/api/scala/index.html#org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator) which let the user evaluate measurements common of binary and multiclass problems, such as, \"f1\" (default), \"weightedPrecision\", \"weightedRecall\", **\"accuracy\"**."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dbbe3118-776b-40a2-8f93-ac147fa1ddb9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Complete the #FILL IN# gaps\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n\n# Compute predictions for test data\npredictions = lsvcModel.transform(testDFBinary)\n\n# Show the computed predictions and compare with the original labels\npredictions.select(\"features\", \"label\", \"prediction\").show(10)\n\n# Define the evaluator method with the corresponding metric and compute the classification error on test data\nevaluator = MulticlassClassificationEvaluator()\naccuracy = evaluator.evaluate(predictions) \n\n# Show the accuracy\nprint(\"Test accuracy = %g\" % (accuracy))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"00c4312b-6643-4e4f-9a00-a43be891e974","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|(784,[129,130,131...|    0|       0.0|\n|(784,[124,125,126...|    0|       0.0|\n|(784,[118,119,120...|    1|       1.0|\n|(784,[156,157,158...|    0|       0.0|\n|(784,[175,176,177...|    1|       1.0|\n|(784,[148,149,150...|    1|       1.0|\n|(784,[121,122,123...|    1|       1.0|\n|(784,[152,153,154...|    0|       0.0|\n|(784,[172,173,174...|    1|       1.0|\n|(784,[163,164,165...|    0|       0.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\n\nTest accuracy = 0.963181\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|(784,[129,130,131...|    0|       0.0|\n|(784,[124,125,126...|    0|       0.0|\n|(784,[118,119,120...|    1|       1.0|\n|(784,[156,157,158...|    0|       0.0|\n|(784,[175,176,177...|    1|       1.0|\n|(784,[148,149,150...|    1|       1.0|\n|(784,[121,122,123...|    1|       1.0|\n|(784,[152,153,154...|    0|       0.0|\n|(784,[172,173,174...|    1|       1.0|\n|(784,[163,164,165...|    0|       0.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\n\nTest accuracy = 0.963181\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\npredictions:pyspark.sql.dataframe.DataFrame = [label: integer, features: udt ... 2 more fields]\n+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|(784,[129,130,131...|    0|       0.0|\n|(784,[124,125,126...|    0|       0.0|\n|(784,[118,119,120...|    1|       1.0|\n|(784,[156,157,158...|    0|       0.0|\n|(784,[175,176,177...|    1|       1.0|\n|(784,[148,149,150...|    1|       1.0|\n|(784,[121,122,123...|    1|       1.0|\n|(784,[152,153,154...|    0|       0.0|\n|(784,[172,173,174...|    1|       1.0|\n|(784,[163,164,165...|    0|       0.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\n\nTest accuracy = 0.950578\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa30fee2-c557-4e20-a0e4-46ea7763c5db","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**2.c) Multiclass SVM**\n\nNow let's solve the original multiclass problem. Despite MLLIB SVM implementation only admits binary problems, MLLIB includes a wrapper to solve [multiclass problems 1 vs. all](https://spark.apache.org/docs/latest/ml-classification-regression.html#one-vs-rest-classifier-aka-one-vs-all) fashion.\n\n**Exercise**: Train a multiclass SVM classifier to classify digit images from \"0\" to \"9\" and compute its accuracy over the test data. For this purpose, use the dataframes trainDF and testDF generated in Sections 1.d) and 1.e).\n\n*Note:* the 1 vs all approach has to train 10 binary classifiers, so the training can take a while (please, be patient)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a6f6ed0a-3e2e-4a48-b079-9fb743c67a14","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC, OneVsRest\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Define your binary classifier\nlsvc = LinearSVC(maxIter=10, regParam=0.1)\n\n# Define the One Vs All Classifier.\novr = OneVsRest(classifier=lsvc)\n\n# train the multiclass model.\novrModel = ovr.fit(trainDF)\n\n# score the model on test data.\npredictions = ovrModel.transform(testDF)\n\n# Show the computed predictions and compare with the original labels\npredictions.select(\"features\", \"label\", \"prediction\").show(10)\n\n# Define the evaluator method with the corresponding metric and compute the classification error on test data\nevaluator = MulticlassClassificationEvaluator()\naccuracy = evaluator.evaluate(predictions) \n\n# Show the accuracy\nprint(\"Test accuracy = %g\" % (accuracy))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0abc3f8a-0f1a-4afc-9025-40f7ddcc20ce","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|(784,[202,203,204...|  7.0|       7.0|\n|(784,[94,95,96,97...|  2.0|       2.0|\n|(784,[128,129,130...|  1.0|       1.0|\n|(784,[124,125,126...|  0.0|       0.0|\n|(784,[150,151,159...|  4.0|       4.0|\n|(784,[156,157,158...|  1.0|       1.0|\n|(784,[149,150,151...|  4.0|       4.0|\n|(784,[179,180,181...|  9.0|       9.0|\n|(784,[129,130,131...|  5.0|       5.0|\n|(784,[209,210,211...|  9.0|       9.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\n\nTest accuracy = 0.871504\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|(784,[202,203,204...|  7.0|       7.0|\n|(784,[94,95,96,97...|  2.0|       2.0|\n|(784,[128,129,130...|  1.0|       1.0|\n|(784,[124,125,126...|  0.0|       0.0|\n|(784,[150,151,159...|  4.0|       4.0|\n|(784,[156,157,158...|  1.0|       1.0|\n|(784,[149,150,151...|  4.0|       4.0|\n|(784,[179,180,181...|  9.0|       9.0|\n|(784,[129,130,131...|  5.0|       5.0|\n|(784,[209,210,211...|  9.0|       9.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\n\nTest accuracy = 0.871504\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\n+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|(784,[202,203,204...|  7.0|       7.0|\n|(784,[94,95,96,97...|  2.0|       2.0|\n|(784,[128,129,130...|  1.0|       1.0|\n|(784,[124,125,126...|  0.0|       0.0|\n|(784,[150,151,159...|  4.0|       4.0|\n|(784,[156,157,158...|  1.0|       1.0|\n|(784,[149,150,151...|  4.0|       4.0|\n|(784,[179,180,181...|  9.0|       9.0|\n|(784,[129,130,131...|  5.0|       4.0|\n|(784,[209,210,211...|  9.0|       9.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\nTest accuracy = 0.8605\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"06afdb3e-1764-4d1a-9301-ecf56cbd6b76","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**2.d) Cross validation of hyperparameters**\n\nAs you know, the linear SVM has a hyper parameter C, which makes a trade off between the margin and the number of wrongly classified samples, and its value becomes critical for the final SVM performance and generalization capability. So far, we have set its value to 0.1 (regParam = 0.1). In this section we are going to use one of the MLLIB parameter tunning utilities to properly adjust its value.\n\nMLLIB includes two objects to carry out this validation process:\n\n* [CrossValidator](https://spark.apache.org/docs/latest/ml-tuning.html#cross-validation)\n* [TrainValidationSplit](https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split)\n\nWhereas 'CrossValidator' runs standard cross validation with a prefixed number of partitions, 'TrainValidationSplit' only evaluates each combination of parameters once. So, 'TrainValidationSplit' is computationally less expensive, but it will not produce as reliable results when the training dataset is not sufficiently large.\n\nDue to the execution a complete cross-validation process would take a long time. We will here perform the adjustment of C using the quick MLLIB version ('TrainValidationSplit') and, in addition, we are going to work again over the binary problem (classification of the digits \"3\" and \"5\").\n\n**Exercise:** Train and evaluate a binary linear SVM classifier when is solving the task of differenciating digits 3 from digits 5 (use the trainDFBinary and testDFBinary generated in Section 2.a)). Adjust its parameter C with a 'TrainValidationSplit' procedure using a 20% of the data for validation and exploring the following range of C values: 100, 10, 1, 0.1, 0.01.\n\n*Note:* You may need to use the method [ParamGridBuilder](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.ParamGridBuilder) to declarate the range of values to explore and after training the TrainValidationSplit model, you can analyze the model_tvs to check the selected value."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9f1f1b3-2001-4089-bafc-bed28b4a7937","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.classification import LinearSVC, OneVsRest\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n\n# Define the  the Classifier\nlsvc = LinearSVC(maxIter=10)\nc_values = [100, 10, 1, 0.1, 0.01]\n\n# We use a ParamGridBuilder to construct a grid of parameters to search over.TrainValidationSplit will \n# try all combinations of values and determine best model using the evaluator.\nparamGrid = ParamGridBuilder().addGrid(lsvc.regParam, c_values).build()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f7989d0-5fd5-43b1-9adb-73aac7b4e6a2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator()\n# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, an Evaluator and the percentage of training/validation data\ntvs = TrainValidationSplit(estimator=lsvc, estimatorParamMaps=paramGrid, evaluator=evaluator, trainRatio=0.80)\n\n# Run TrainValidationSplit to choose the best parameter. It also trains the final model for the selected value of C.\nmodel_tvs = tvs.fit(trainDFBinary)\n\n# Check the validation accuracy over each C value \nprint(\"Validation accuracies:\")\nprint(model_tvs.validationMetrics)\n\n# Make predictions on test data. \npredictions = model_tvs.transform(testDFBinary)\n    \n# Define the evaluator method with the corresponding metric and compute the classification error on test data\nevaluator = MulticlassClassificationEvaluator()\naccuracy = evaluator.evaluate(predictions)\n\n# Show the accuracy\nprint(\"Test accuracy = %g\" % (accuracy))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a8a81119-565b-41ca-ad1a-1a834fde32c4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Validation accuracies:\n[0.3567762945285504, 0.9413298247234687, 0.9539296458099054, 0.9573956604877858, 0.956957296052668]\nTest accuracy = 0.963181\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Validation accuracies:\n[0.3567762945285504, 0.9413298247234687, 0.9539296458099054, 0.9573956604877858, 0.956957296052668]\nTest accuracy = 0.963181\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**_The answer should be_:**\n<pre><code>\nValidation accuracies:\n[0.930959617889709, 0.9452887537993921, 0.9444203213200174, 0.9448545375597047, 0.9444203213200174, 0.9448545375597047]\nTest accuracy = 0.950578\n</code></pre>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9f5e930c-f6b9-4684-91ea-9e684daf85f2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### HOMEWORK: feature selection over Spark\nLet's consider again the binary classification problem which has to differenciate in the digits \"3\" from the digits \"5\". Do you think that all the pixels in the image are equally important for this task? Efectivelly, the answer is **no**. In fact, there are pixels, like those in the background, that are always 0 and others that do not help us to differenciate a number \"3\" from a number \"5\" because they correspond to common strokes of both digits. \n\nIn this part of the practice we will use a [two sample t-test](https://en.wikipedia.org/wiki/Student%27s_t-test#Independent_two-sample_t-test) to analyze the relevance of each pixel in this classification task and, then, select the most discriminating pixels and solve the classification problem with them alone.\n\nThe two sample t-test analizes whether 2 independent populations have identical average (expected) values and it provides a t-value indicating the relative difference between means. In our case, we will analyze for each pixel whether its mean value over the digits 3 is different from that over the digits 5.\n\nNext cell includes the code to compute these t-values, but this example code is not implemented over Spark and it can only be run over a single machine (note that the code starts by taking a subset the data to the driver). So, you have to adapt this code to Spark, so that it can be run in a distributed way using the complete data.\n\n*Note:* The example code works over 1000 data, so you can find slight differences when you run it over the complete dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b9e2bd3e-376b-42a9-a658-c90ba4684eb0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import numpy as np\nfrom scipy.stats import t\n\n###################################################\n# EXAMPLE OF THE T-TEST FOR FEATURE SELECTION\n# THIS CODE RUNS ON THE DRIVER \n# ADAPT IT TO BE RUN DISTRIBUTEDLY\n###################################################\n\n# Collect the training data \ntrainingData = trainDFBinary.take(1000)\n\n# Get the features of the data belonging to class 0, compute its mean \ndata0 = np.array([data.features for data in trainingData if data.label==0])\nmean0 = np.mean(data0, axis=0)\n\n# Get the features of the data belonging to class 1, compute its mean \ndata1 = np.array([data.features for data in trainingData if data.label==1])\nmean1 = np.mean(data1, axis=0)\n\n# Compute common variance\nstd_common = np.std(np.concatenate((data0 ,data1)), axis=0)\n\n# Compute the number of data per class\nN0 = data0.shape[0]\nN1 = data1.shape[0]\n\n# Compute t-values \nt_values= np.divide((mean0-mean1), np.sqrt(1./N0 + 1./N1)*std_common)\n# Solving nan problems (some pixels are constant for all the data, so their means are 0, its std its 0 and its t_value is nan)\nt_values[np.isnan(t_values)]=0\n\n# We can plot the t_values and their absolute values\nfig = plot_data([t_values,np.abs(t_values)], h, w)\ndisplay(fig)\n\n# Ranking t-values\n# The most discriminating pixels have very large or very small t values, so we rank over their absolute value\n# np.argsort ranks in ascending order, so we invert the result to have the most discriminative pixels in the first positions\npos_relevant = np.argsort(np.abs(t_values))[::-1]\n\n# We select the 200 most relevant pixels and built the new data set\npos_sel = pos_relevant[:200]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0cfe4420-792c-487b-89d0-6eaa0513b2e4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Finally, analize the performance of the binary SVM when it is trained with the subset of 200 most relevant features. You can try to analyze the classifier performance for different number of selected features (for instance, 10, 100 and 200).\n\n*Note:* you may need the method [VectorSlicer](https://spark.apache.org/docs/latest/ml-features.html#vectorslicer) to apply a feature selection mask over the train and test DFs."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5cfe80dd-16e2-4029-a3f6-7967e9e8ca2a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# WRITE YOUR CODE HERE"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6d9e818e-7f51-41a3-b576-9b62fe48b442","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Classifiers_Spark (1)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2716345349644145}},"nbformat":4,"nbformat_minor":0}
